[{"path":"index.html","id":"info","chapter":"1201.info","heading":"1201.info","text":"site contains supplemental materials Stat 1201, mainly: 1) clarifications sections cover textbook (Devore, Probability Statistics Engineering Sciences 9th edition), 2) R code, 3) links helpful resources online. way substitute materials available CourseWorks.find additional online resources helpful class, please create issue send email ’ll add resource. Let know well find typos mistakes.Note ’re encouraged look ahead, sure circle back sections ’re covered class since content may added modified slightly.","code":""},{"path":"index.html","id":"general-study-tips","chapter":"1201.info","heading":"General study tips","text":"website book Make Stick offers summary experimentally tested study strategies. tl;dr :working problems better reviewing notes / textbookworking problems better reviewing notes / textbookdoing mixed reviews better focusing one type problem timedoing mixed reviews better focusing one type problem timelearning hard work; seems easy study strategy might effectivelearning hard work; seems easy study strategy might effectivemaking mistakes learning useful strategy (don’t wait ’ve mastered examples try problem)making mistakes learning useful strategy (don’t wait ’ve mastered examples try problem)’ve likely heard lot ideas , ’s worth really thinking putting practice.advice:’re reading textbook working problem set, keep list questions. Challenge thinking problem differ changed setup.’re reading textbook working problem set, keep list questions. Challenge thinking problem differ changed setup.Try creating questions solving .Try creating questions solving .Try solving problems multiple ways.Try solving problems multiple ways.Learn variety sources: class, textbook, Cartoon Guide, etc. find differences, ask.Learn variety sources: class, textbook, Cartoon Guide, etc. find differences, ask.","code":""},{"path":"index.html","id":"installing-r","chapter":"1201.info","heading":"Installing R","text":"need install two applications: R RStudio:R – programming language – available :https://cran.r-project.orgRStudio – integrated development environment (IDE) makes much easier use R. optional highly recommended. app open use R. Choose free version RStudio Desktop:https://www.rstudio.com/products/rstudio/download/#download","code":""},{"path":"index.html","id":"getting-started-with-r-working-in-the-console","chapter":"1201.info","heading":"Getting Started with R: Working in the Console","text":"first step getting started getting comfortable working RStudio console. works like calculator sense work saved. following:","code":""},{"path":"index.html","id":"watch-the-video","chapter":"1201.info","heading":"Watch the video","text":"","code":""},{"path":"index.html","id":"quick-review-of-material-covered-in-the-video-plus-additional-examples","chapter":"1201.info","heading":"Quick review of material covered in the video, plus additional examples","text":"Working console pane similar using calculator: line code executed press enter. Note work saved approach.Assigning variableDrawing stem leaf plotBasic operations:Working vectors:Expected value:","code":"\n3 + 4## [1] 7\n3 - 4## [1] -1\n3 * 4## [1] 12\n3 / 4## [1] 0.75\n3^4## [1] 81\nsqrt(3)## [1] 1.732051\nx <- 1:5\nx## [1] 1 2 3 4 5\nsum(x)## [1] 15\ncumsum(x)## [1]  1  3  6 10 15\npx <- x*.05 + .05\npx## [1] 0.10 0.15 0.20 0.25 0.30\nx*px## [1] 0.1 0.3 0.6 1.0 1.5\nsum(x*px)## [1] 3.5"},{"path":"index.html","id":"more-examples","chapter":"1201.info","heading":"More examples","text":"Read try examples Chapter 1 Introduction R","code":""},{"path":"index.html","id":"creating-graphs-saving-your-work","chapter":"1201.info","heading":"Creating Graphs, Saving your work","text":"Video","code":""},{"path":"index.html","id":"saving-code-as-an-.r-file","chapter":"1201.info","heading":"Saving code as an .R file","text":"(Also covered video )Saving method saves code, output. two methods creating .html documents contain code output:","code":""},{"path":"index.html","id":"convert-.r-file-to-.html","chapter":"1201.info","heading":"Convert .R file to .html","text":"(Also covered video )","code":""},{"path":"index.html","id":"contact","chapter":"1201.info","heading":"Contact","text":"Joyce Robbins:\nColumbia ProfileGitHub","code":""},{"path":"index.html","id":"license","chapter":"1201.info","heading":"License","text":"work licensed Creative Commons Attribution-ShareAlike 4.0 International License.","code":""},{"path":"ch.-1-descriptive-statistics.html","id":"ch.-1-descriptive-statistics","chapter":"Ch. 1 Descriptive Statistics","heading":"Ch. 1 Descriptive Statistics","text":"Sections covered: ","code":""},{"path":"ch.-1-descriptive-statistics.html","id":"populations-samples-and-processes","chapter":"Ch. 1 Descriptive Statistics","heading":"1.1 Populations, Samples, and Processes","text":"","code":""},{"path":"ch.-1-descriptive-statistics.html","id":"pictorial-and-tabular-methods-in-descriptive-statistics","chapter":"Ch. 1 Descriptive Statistics","heading":"1.2 Pictorial and Tabular Methods in Descriptive Statistics","text":"Skip: Example 1.7, p. 15 (double-digit leaves)Skip: “Dotplots,” pp. 15-16Stem--leaf display:Note histograms drawn unbinned data. R binning process drawing histogram.Frequency histogram:Density histogram:Cumulative frequency histogramFor type histogram, need access bin counts, order calculate cumulative frequencies. hist() function returns values, assigned variable:particular information want $counts:cumulative frequencies :plot , need use bar chart, histogram, since already y-axis values:Cleaned :","code":"\nprices <- c(379, 425, 450, 450, 499, 529, 535, 535, 545, 599, 665,\n            675, 699, 699, 725, 725, 745, 799)\n\nstem(prices)## \n##   The decimal point is 2 digit(s) to the right of the |\n## \n##   3 | 8\n##   4 | 355\n##   5 | 03445\n##   6 | 078\n##   7 | 00335\n##   8 | 0\nprices <- c(379, 425, 450, 450, 499, 529, 535, 535, 545, 599, 665,\n            675, 699, 699, 725, 725, 745, 799)\n\nhist(prices)\nhist(prices, breaks = c(300, 400, 500, 600, 700, 800),\n     col = \"lightblue\")\nprices <- c(379, 425, 450, 450, 499, 529, 535, 535, 545, 599, 665,\n            675, 699, 699, 725, 725, 745, 799)\n\nhist(prices, freq = FALSE, \n     breaks = c(300, 400, 500, 600, 700, 800),\n     col = \"lightblue\", las = 1)\nx <- c(1, 1, 1, 1, 1, 5, 5, 5, 7, 7, 8)\nmyhistdata <- hist(x)\nmyhistdata## $breaks\n## [1] 1 2 3 4 5 6 7 8\n## \n## $counts\n## [1] 5 0 0 3 0 2 1\n## \n## $density\n## [1] 0.45454545 0.00000000 0.00000000 0.27272727 0.00000000 0.18181818 0.09090909\n## \n## $mids\n## [1] 1.5 2.5 3.5 4.5 5.5 6.5 7.5\n## \n## $xname\n## [1] \"x\"\n## \n## $equidist\n## [1] TRUE\n## \n## attr(,\"class\")\n## [1] \"histogram\"\nmyhistdata$counts## [1] 5 0 0 3 0 2 1\ncumsum(myhistdata$counts)## [1]  5  5  5  8  8 10 11\nbarplot(cumsum(myhistdata$counts))\nbarplot(cumsum(myhistdata$counts),\n        col = \"lightblue\", \n        space = 0,  # remove gaps between bars\n        las = 1, # make all tick mark labels horizontal\n        ylim = c(0, 12), # make the y-axis longer\n        names.arg = myhistdata$mids\n        )"},{"path":"ch.-1-descriptive-statistics.html","id":"measures-of-location","chapter":"Ch. 1 Descriptive Statistics","heading":"1.3 Measures of location","text":"Skip: Example 1.16, p. 33 (trimmed mean)Skip: “Categorical Data Sample Proportions,” p. 34 (’ll return topic later.)","code":"\nprices <- c(379, 425, 450, 450, 499, 529, 535, 535, 545, 599, 665,\n            675, 699, 699, 725, 725, 745, 799)\n\nmean(prices)## [1] 593.2222\nmedian(prices)## [1] 572\n## quartiles\nquantile(prices)##    0%   25%   50%   75%  100% \n## 379.0 506.5 572.0 699.0 799.0\n## trimmed mean\nmean(prices, trim = .1) ## 10% trimmed mean## [1] 593.75"},{"path":"ch.-1-descriptive-statistics.html","id":"measures-of-variability","chapter":"Ch. 1 Descriptive Statistics","heading":"1.4 Measures of variability","text":"Skip: extreme outliers (p. 42)define outliers boxplots observations 1.5 times fourth spread closest fourth. may indicated either solid open circle (contrast book uses one mild outliers extreme outliers.)Sample variance:Sample standard deviation:Five number summary(min, lower-hinge, median, upper-hinge, max)Boxplots","code":"\nprices <- c(379, 425, 450, 450, 499, 529, 535, 535, 545, 599, 665,\n            675, 699, 699, 725, 725, 745, 799)\n\nvar(prices)## [1] 15981.48\nsqrt(var(prices))## [1] 126.4179\nsd(prices)## [1] 126.4179\nfivenum(prices)## [1] 379 499 572 699 799\nprices <- c(379, 425, 450, 450, 499, 529, 535, 535, 545,\n            599, 665, 675, 699, 699, 725, 725, 745, 799)\n\nboxplot(prices)\nboxplot(prices, horizontal = TRUE)\nPTSD <- c(10, 20, 25, 28, 31, 35, 37, 38, 38, 39, 39, 42, 46)\n\nHealthy <- c(23, 39, 40, 41, 43, 47, 51, 58, 63, 66, 67, 69, 72)\n\ndf <- data.frame(Healthy, PTSD)\n\nboxplot(df, horizontal = TRUE)"},{"path":"ch.-1-descriptive-statistics.html","id":"practice-exercises","chapter":"Ch. 1 Descriptive Statistics","heading":"Practice Exercises","text":"Using built-dataset ToothGrowth R, visualize data comment effectiveness different functions context.[Ans] head(): directly see dataset looks; useful dataset large ’s difficult display rows columns together.fivenum(): returns minimum value, lower fourth, median, upper fourth, maximum valueboxplot(): visualizes five number summary plus outliers. (’s clear ToothGrowth data skewed.)stem(): compares number data points fall different bins. (can see values 20 29.)hist(): draws histogram – values grouped binscumsum(): takes vector returns cumulative sums","code":"\n# The first 5 rows of the data\nhead(ToothGrowth, 5)##    len supp dose\n## 1  4.2   VC  0.5\n## 2 11.5   VC  0.5\n## 3  7.3   VC  0.5\n## 4  5.8   VC  0.5\n## 5  6.4   VC  0.5\n# Five number summary\nfivenum(ToothGrowth$len)## [1]  4.20 12.55 19.25 25.35 33.90\n# Boxplot \n# '$' extracts the column by name\nboxplot(ToothGrowth$len) \n# Stem-and-leaf Plot\nstem(ToothGrowth$len)## \n##   The decimal point is 1 digit(s) to the right of the |\n## \n##   0 | 4\n##   0 | 5667789\n##   1 | 00001124\n##   1 | 55555677777899\n##   2 | 001222333344\n##   2 | 55566666667779\n##   3 | 0134\n# Histogram\nh <- hist(ToothGrowth$len)\n# Cumulative Histogram\nh$counts <- cumsum(h$counts)\nplot(h)"},{"path":"ch.-2-probability.html","id":"ch.-2-probability","chapter":"Ch. 2 Probability","heading":"Ch. 2 Probability","text":"Sections covered: 2.1, 2.2, 2.3, 2.5(2.4 covered later semester)","code":""},{"path":"ch.-2-probability.html","id":"sample-spaces-and-events","chapter":"Ch. 2 Probability","heading":"2.1 Sample Spaces and Events","text":"","code":""},{"path":"ch.-2-probability.html","id":"humor","chapter":"Ch. 2 Probability","heading":"Humor","text":"Source: https://twitter.com/bcrypt/status/1074415553266122752/photo/1","code":""},{"path":"ch.-2-probability.html","id":"axioms-interpretations-and-properties-of-probability","chapter":"Ch. 2 Probability","heading":"2.2 Axioms, Interpretations, and Properties of Probability","text":"","code":""},{"path":"ch.-2-probability.html","id":"counting-techniques","chapter":"Ch. 2 Probability","heading":"2.3 Counting Techniques","text":"","code":""},{"path":"ch.-2-probability.html","id":"r","chapter":"Ch. 2 Probability","heading":"R","text":"FactorialCombinations“5 choose 2” = choose 2 items 5PermutationsThere built-function calculate permutations. can multiply number combinations k!.Ex. Number permutations size 2 can formed 5 distinct items:can create function :","code":"\nfactorial(5)## [1] 120\nchoose(5, 2)## [1] 10\nchoose(5,2)*factorial(2)## [1] 20\nperm <- function(n, k) {choose(n,k)*factorial(k)}\n\nperm(5,2)## [1] 20"},{"path":"ch.-2-probability.html","id":"independence","chapter":"Ch. 2 Probability","heading":"2.5 Independence","text":"Skip everything “Multiplication Rule” p. 86 (return conditional probability later semester)","code":""},{"path":"ch.-3-discrete-distributions.html","id":"ch.-3-discrete-distributions","chapter":"Ch. 3 Discrete Distributions","heading":"Ch. 3 Discrete Distributions","text":"Sections covered: 3.1 - 3.6Skip: 3.6 “Poisson Distribution Limit” (pp. 132-33) “Poisson Process” (pp. 134-135)","code":""},{"path":"ch.-3-discrete-distributions.html","id":"expected-value","chapter":"Ch. 3 Discrete Distributions","heading":"3.3 Expected value","text":"","code":"\nx <- 1:5\nx## [1] 1 2 3 4 5\npx <- c(.1, .15, .2, .25, .3)\npx## [1] 0.10 0.15 0.20 0.25 0.30\nx*px## [1] 0.1 0.3 0.6 1.0 1.5\nsum(x*px)    # E(X)## [1] 3.5"},{"path":"ch.-3-discrete-distributions.html","id":"variance","chapter":"Ch. 3 Discrete Distributions","heading":"3.3 Variance","text":"","code":"\nx - 3.5## [1] -2.5 -1.5 -0.5  0.5  1.5\n(x - 3.5)^2## [1] 6.25 2.25 0.25 0.25 2.25\n((x - 3.5)^2)*px## [1] 0.6250 0.3375 0.0500 0.0625 0.6750\nsum(((x - 3.5)^2)*px)   # V(X)## [1] 1.75"},{"path":"ch.-3-discrete-distributions.html","id":"variance-alternative-method","chapter":"Ch. 3 Discrete Distributions","heading":"3.3 Variance (alternative method)","text":"","code":"\nx## [1] 1 2 3 4 5\npx## [1] 0.10 0.15 0.20 0.25 0.30\nx^2## [1]  1  4  9 16 25\n(x^2)*px## [1] 0.1 0.6 1.8 4.0 7.5\nsum((x^2)*px)  # E(X^2)## [1] 14\n14-3.5^2     # E(X^2) - [E(X)]^2## [1] 1.75"},{"path":"ch.-3-discrete-distributions.html","id":"binominal-theorem","chapter":"Ch. 3 Discrete Distributions","heading":"3.4 Binominal Theorem","text":"p. 121 Using binomial tables cumulative distribution function (cdf) optional; may use R (see ) www.stattrek.com instead.tests need calculate values. can leave answers summations, example:\\(\\Sigma_{x=0}^6 \\left(\\begin{array}{c}12\\\\ x\\end{array}\\right)(.3^x)(.7^{12-x})\\)","code":""},{"path":"ch.-3-discrete-distributions.html","id":"r-1","chapter":"Ch. 3 Discrete Distributions","heading":"R","text":"Probability mass function (pmf)\\(P(X = x)\\)Direct methodCumulative distribution function (cdf)\\(P(X \\leq x)\\)Find \\(P(2 \\leq X \\leq 4)\\) given \\(p = .7, n = 15\\)(Using pmf instead:)Graphing binomial pmf:ex. \\(p = .7, n = 10\\)","code":"\nchoose(8, 3)    # \"8 choose 3\"## [1] 56\n56*.6^3*.4^5     # P(X = 3) given n = 8, p = .6## [1] 0.123863\ndbinom(3, 8, .6)     # P(X = 3) given n = 8, p = .6## [1] 0.123863\npbinom(4, 15, .7) - pbinom(1, 15, .7)## [1] 0.0006717175\ndbinom(2, 15, .7) + dbinom(3, 15, .7) + dbinom(4, 15, .7)## [1] 0.0006717175\npx <- dbinom(0:10, 10, .7)\n# adding las = 1 turns the y-axis tick mark labels horizontal, which are easier to read\nbarplot(px, names.arg = 0:10, las = 1, col = \"lightblue\")"},{"path":"ch.-3-discrete-distributions.html","id":"hypergeometric","chapter":"Ch. 3 Discrete Distributions","heading":"3.5 Hypergeometric","text":"Note notation R uses different Devore textbook:Example (p. 127)Devore: h(x; n, M, N)P(X = 2) = h(2; 10, 5, 25) –>","code":"\ndhyper(x = 2, m = 5, n = 20, k = 10)## [1] 0.3853755"},{"path":"ch.-3-discrete-distributions.html","id":"poisson","chapter":"Ch. 3 Discrete Distributions","heading":"3.6 Poisson","text":"Example (p. 132)p(3;2) =F(3;2) =","code":"\ndpois(3,2)## [1] 0.180447\nppois(3, 2)## [1] 0.8571235"},{"path":"ch.-3-discrete-distributions.html","id":"practice-exercises-1","chapter":"Ch. 3 Discrete Distributions","heading":"Practice Exercises","text":"(Binomial) Suppose probability car accident involving single vehicle .7. 15 accidents randomly selected, probability 2 4, inclusive, involve single vehicle? (slides)(Binomial) particular telephone number used receive voice calls fax messages. Suppose 25% incoming calls involve fax messages, consider sample 25 incoming calls. probability \n6 calls involve fax message?\nExactly 6 calls involve fax message?\nleast 6 calls involve fax message?\nexpected number calls among 25 involve fax message?\nstandard deviation number among 25 calls involve fax message?\nprobability number calls among 25 involve fax transmission exceeds expected number 2 standard deviations? (Textbook 50-51)\n(Binomial) particular telephone number used receive voice calls fax messages. Suppose 25% incoming calls involve fax messages, consider sample 25 incoming calls. probability thatAt 6 calls involve fax message?6 calls involve fax message?Exactly 6 calls involve fax message?Exactly 6 calls involve fax message?least 6 calls involve fax message?least 6 calls involve fax message?expected number calls among 25 involve fax message?expected number calls among 25 involve fax message?standard deviation number among 25 calls involve fax message?standard deviation number among 25 calls involve fax message?probability number calls among 25 involve fax transmission exceeds expected number 2 standard deviations? (Textbook 50-51)probability number calls among 25 involve fax transmission exceeds expected number 2 standard deviations? (Textbook 50-51)(Hypergeometric) geologist collected 8 specimens basaltic rock 12 specimens granite. geologist instructs laboratory assistant randomly select 15 specimens analysis.\nprobability specimens one two types rock selected analysis?\nprobability number granite specimens selected analysis within 1 standard deviation mean value? (Textbook 71)\n(Hypergeometric) geologist collected 8 specimens basaltic rock 12 specimens granite. geologist instructs laboratory assistant randomly select 15 specimens analysis.probability specimens one two types rock selected analysis?probability specimens one two types rock selected analysis?probability number granite specimens selected analysis within 1 standard deviation mean value? (Textbook 71)probability number granite specimens selected analysis within 1 standard deviation mean value? (Textbook 71)(Negative Binomial) probability randomly selected box certain type cereal particular prize .2. Suppose purchase box box obtained two prizes.\nprobability purchase \\(x\\) boxes desired prize?\nprobability purchase four boxes?\nprobability purchase four boxes?\nmany boxes without desired prize expect purchase? many boxes expect purchase? (Textbook 75, homework)\n(Negative Binomial) probability randomly selected box certain type cereal particular prize .2. Suppose purchase box box obtained two prizes.probability purchase \\(x\\) boxes desired prize?probability purchase \\(x\\) boxes desired prize?probability purchase four boxes?probability purchase four boxes?probability purchase four boxes?probability purchase four boxes?many boxes without desired prize expect purchase? many boxes expect purchase? (Textbook 75, homework)many boxes without desired prize expect purchase? many boxes expect purchase? (Textbook 75, homework)Let x number boxes without prizes purchased, \\(p = {x+2-1\\choose1}(.2^2)(.8 ^x)\\)(Poisson) Suppose number drivers travel particular origin destination designated time period Poisson distribution parameter \\(\\mu = 20\\). probability number drivers \n10?\n10?\nwithin 2 standard deviations mean value?\n(Textbook 81)(Poisson) Suppose number drivers travel particular origin destination designated time period Poisson distribution parameter \\(\\mu = 20\\). probability number drivers willBe 10?10?10?10?within 2 standard deviations mean value?within 2 standard deviations mean value?(Textbook 81)","code":"\ndbinom(2, 15, .7) + dbinom(3, 15, .7) + dbinom(4, 15, .7)## [1] 0.0006717175\npbinom(4, 15, .7) - pbinom(1, 15, .7)## [1] 0.0006717175\npbinom(6, 25, .25)## [1] 0.5610981\ndbinom(6, 25, .25)## [1] 0.1828195\n1 - pbinom(5, 25, .25)## [1] 0.6217215\nE <- 25*.25\nVar <- 25*.25*.75\npbinom(floor(E+2*sqrt(Var)), 25, .25)## [1] 0.9703301\ndhyper(8, 8, 12, 15) + dhyper(3, 8, 12, 15)## [1] 0.05469556\nmean_g <- 15*12/20\nsd_g <- sqrt(20*(12/20)*(8/20))\npbinom(mean_g + sd_g, 15, 12/20)-pbinom(mean_g - sd_g, 15, 12/20)## [1] 0.8144507\ndnbinom(2, 2, .2)## [1] 0.0768\ndnbinom(2, 2, .2) + dnbinom(1, 2, .2) + dnbinom(0, 2, .2)## [1] 0.1808\n2*.8/.2## [1] 8\n# 8 boxes without desired prize, 10 boxes in total\nppois(10, 20) # a## [1] 0.01081172\ndpois(10, 20) # b1## [1] 0.005816307\n((exp(1)^-20)*(20^10))/factorial(10) # b2## [1] 0.005816307\nppois(20 + 2*sqrt(20),20) - ppois(20 - 2*sqrt(20), 20) # c## [1] 0.9442797"},{"path":"ch.-4-continuous-random-variables-and-probability-distributions.html","id":"ch.-4-continuous-random-variables-and-probability-distributions","chapter":"Ch. 4 Continuous Random Variables and Probability Distributions","heading":"Ch. 4 Continuous Random Variables and Probability Distributions","text":"Sections covered: 4.1, 4.2, 4.3","code":""},{"path":"ch.-4-continuous-random-variables-and-probability-distributions.html","id":"probability-density-functions","chapter":"Ch. 4 Continuous Random Variables and Probability Distributions","heading":"4.1 Probability density functions","text":"","code":""},{"path":"ch.-4-continuous-random-variables-and-probability-distributions.html","id":"r-2","chapter":"Ch. 4 Continuous Random Variables and Probability Distributions","heading":"R","text":"Simulating uniform distributionRandomly choose one number distribution:\\(f(x) = .2\\) \\(0 \\leq x \\leq 5\\), 0 otherwise.Take average 1000 picks:Draw histogram 1000 picks:","code":"\nrunif(n = 1, min = 0, max = 5)## [1] 2.286024\nx <- runif(n = 1000, min = 0, max = 5)\nmean(x)## [1] 2.469152\nhist(x, las = 1, col = \"lightblue\")"},{"path":"ch.-4-continuous-random-variables-and-probability-distributions.html","id":"cumulative-distribution-functions-and-expected-values","chapter":"Ch. 4 Continuous Random Variables and Probability Distributions","heading":"4.2 Cumulative Distribution Functions and Expected Values","text":"Using R help calculations Example 4.7, p. 149Define function cdf (integration ):Find \\(F(1.5) - F(1)\\)","code":"\nF <- function(x) (x/8) + (3/16)*x^2\nF(1.5) - F(1)## [1] 0.296875"},{"path":"ch.-4-continuous-random-variables-and-probability-distributions.html","id":"the-normal-distribution","chapter":"Ch. 4 Continuous Random Variables and Probability Distributions","heading":"4.3 The Normal Distribution","text":"Interactive normal distribution – change \\(\\mu\\) \\(\\sigma\\) see happens.Normal table – pdf form viewing online, downloading /printingOnline normal distribution lookup – enter \\(z\\) calculate \\(F(z) = P(Z \\leq z)\\).many online normal distribution calculators. Note often given choice finding \\(P(Z \\leq z)\\), \\(P(Z \\geq z)\\), \\(P(0 \\leq Z \\leq z)\\), etc., careful. consistent normal tables textbook / class, choose \\(P(Z \\leq z)\\).Due rounding differences \\(z\\) \\(P(Z \\leq z)\\), solutions using technology vary using normal table. methods fine.","code":""},{"path":"ch.-4-continuous-random-variables-and-probability-distributions.html","id":"r-3","chapter":"Ch. 4 Continuous Random Variables and Probability Distributions","heading":"R","text":"\\(P(Z \\leq -1)\\)Unless specified otherwise, pnorm uses mean 0 standard deviation 1 (standard normal).\\(P(X \\leq 37)\\) given \\(\\mu = 40\\) \\(\\sigma = 2\\)\\(P(X > 39)\\)Find 75th percentile standard normal distribution:Find 75th percentile normally distribution population mean 40 standard deviation 2:","code":"\npnorm(-1)## [1] 0.1586553\npnorm(37, mean = 40, sd = 2)## [1] 0.0668072\npnorm((37-40)/2)## [1] 0.0668072\n1 - pnorm(39, mean = 40, sd = 2)## [1] 0.6914625\nqnorm(.75)## [1] 0.6744898\nqnorm(.75, mean = 40, sd = 2)## [1] 41.34898\n40 + qnorm(.75)*2## [1] 41.34898"},{"path":"ch.-4-continuous-random-variables-and-probability-distributions.html","id":"practice-exercises-2","chapter":"Ch. 4 Continuous Random Variables and Probability Distributions","heading":"Practice Exercises","text":"(pdf, E V) \\(X\\) continuous random variable probability distrbution \\(f(x)=.06x + .05\\) \\(0\\leq x \\leq 5\\).\nprobability \\(2\\leq x\\leq 4\\)?\nprobability \\(x = 4\\)?\nexpected value \\(X\\)?\nvariance X?\n(pdf, E V) \\(X\\) continuous random variable probability distrbution \\(f(x)=.06x + .05\\) \\(0\\leq x \\leq 5\\).probability \\(2\\leq x\\leq 4\\)?probability \\(x = 4\\)?expected value \\(X\\)?variance X?[Ans]\n. Integrating hand: \\(f(x)=.06x + .05\\), get \\(F(x) = .03x^2+.05x\\).00Integrate \\(x\\cdot f(x) = x(.06x+.05)=.06x^2+.05x\\), get \\(H(x) = .02x^3+.025x^2\\).Integrate \\(x\\cdot f(x) = x(.06x+.05)=.06x^2+.05x\\), get \\(H(x) = .02x^3+.025x^2\\).\\(V(X) = E(X^2)-[E(X)]^2\\).\nIntegrate \\(x^2\\cdot f(x) = x^2(.06x+.05)=.06x^3+.05x^2\\), get \\(G(x) = .015x^4+\\frac{.05}3x^3\\).(Standard Normal, pnorm) driver’s reaction time -traffic response brake signal can modeled normal distribution mean value 1.25 sec standard deviation .46 sec. (Textbook 4.16)\nprobability reaction time 1.00 sec 1.75 sec?\nprobability reaction time exceeds 2.00 sec?\n(Standard Normal, pnorm) driver’s reaction time -traffic response brake signal can modeled normal distribution mean value 1.25 sec standard deviation .46 sec. (Textbook 4.16)probability reaction time 1.00 sec 1.75 sec?probability reaction time 1.00 sec 1.75 sec?probability reaction time exceeds 2.00 sec?probability reaction time exceeds 2.00 sec?(Nonstandard Normal, qnorm) Data collected experiment specified initial crack\nlength propose normal distribution mean value 5.496 mm standard deviation .067 mm. model, value final crack depth exceeded .5% cracks? (Textbook 4.18)(Binom Appproximation) Suppose 25% students large public university receive financial aid. Let \\(X\\) number students random sample size 50 receive financial\naid, sothat p = .25. probability 10 students receive aid? (Textbook 4.20)","code":"\nF <- function(x) 0.03*x^2 + 0.05*x\nx <- runif(n = 1000, min = 0, max = 5)\nF(4) - F(2)## [1] 0.46\nH <- function(x) 0.02*x^3 + 0.025*x^2\nH(5)-H(0) ## [1] 3.125\nE <- H(5)-H(0)\nG <- function(x) .015*(x^4)+(.05/3)*(x^3)\nG(5)-G(0)-E^2## [1] 1.692708\npnorm((1.75-1.25)/0.46) - pnorm((1-1.25)/0.46)## [1] 0.5680717\n1 - pnorm((2-1.25)/0.46)## [1] 0.05150482\n# alternatively\npnorm(-(2-1.25)/0.46)## [1] 0.05150482\nqnorm(0.995, 5.496, .067)## [1] 5.668581\n# binom distribution calculation\npbinom(10, size = 50, prob = 0.25) ## [1] 0.2622023\n# normal approximation of binom\npnorm((10 + .5 - 50*.25)/sqrt(50*.25*.75))## [1] 0.2568146"},{"path":"ch.-4-continuous-random-variables-and-probability-distributions.html","id":"extra-practice-chapters-1---4","chapter":"Ch. 4 Continuous Random Variables and Probability Distributions","heading":"Extra Practice Chapters 1 - 4","text":"QuestionsSolutions","code":""},{"path":"ch.-5-random-samples.html","id":"ch.-5-random-samples","chapter":"Ch. 5 Random Samples","heading":"Ch. 5 Random Samples","text":"Sections covered: 5.3, 5.4, 5.5","code":""},{"path":"ch.-5-random-samples.html","id":"the-distribution-of-the-sample-mean","chapter":"Ch. 5 Random Samples","heading":"5.4 The Distribution of the Sample Mean","text":"Central Limit Theorem visualization: http://mfviz.com/central-limit/","code":""},{"path":"ch.-5-random-samples.html","id":"the-distribution-of-a-linear-combination","chapter":"Ch. 5 Random Samples","heading":"5.5 The Distribution of a Linear Combination","text":"Skip (now): formula (5.11) – variance linear combination assuming independence \\(X_i\\)’s.","code":""},{"path":"ch.-6-point-estimation.html","id":"ch.-6-point-estimation","chapter":"Ch. 6 Point Estimation","heading":"Ch. 6 Point Estimation","text":"Sections covered: 6.1","code":""},{"path":"ch.-6-point-estimation.html","id":"some-general-concepts-of-point-estimation","chapter":"Ch. 6 Point Estimation","heading":"6.1 Some General Concepts of Point Estimation","text":"Skip everything beginning “Complications” p. 257","code":""},{"path":"ch.-7-statistical-intervals-based-on-a-single-sample.html","id":"ch.-7-statistical-intervals-based-on-a-single-sample","chapter":"Ch. 7 Statistical Intervals Based on a Single Sample","heading":"Ch. 7 Statistical Intervals Based on a Single Sample","text":"Sections covered: 7.1, 7.2, 7.3","code":""},{"path":"ch.-7-statistical-intervals-based-on-a-single-sample.html","id":"basic-properties-of-confidence-intervals","chapter":"Ch. 7 Statistical Intervals Based on a Single Sample","heading":"7.1 Basic Properties of Confidence Intervals","text":"Skip: “Deriving Confidence Interval”, pp. 282-284; “Bootstrap Confidence Intervals”, p. 284","code":""},{"path":"ch.-7-statistical-intervals-based-on-a-single-sample.html","id":"large-sample-confidence-intervals-for-a-population-mean-and-proportion","chapter":"Ch. 7 Statistical Intervals Based on a Single Sample","heading":"7.2 Large-Sample Confidence Intervals for a Population Mean and Proportion","text":"may use: \\(\\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}\\hat{q}}{n}}\\), rather formula (7.10) blue box p. 289 large sample confidence intervals proportions, skip p. 290You may use method class \\(n = \\frac{4z^2\\hat{p}\\hat{q}}{w^2}\\) minimum \\(n\\) needed ensure particular confidence interval width proportions, rather formula (7.12) – appear p. 291. noted Example 7.9 p. 291, easier formula gives slightly different answer (385 instead 381).Additional textbook material CI proportions“Hear Margin Error Plus Minus 3 Percent, Think 7 Instead”, New York Times, Oct 5, 2016.","code":""},{"path":"ch.-7-statistical-intervals-based-on-a-single-sample.html","id":"intervals-based-on-a-normal-population-distribution","chapter":"Ch. 7 Statistical Intervals Based on a Single Sample","heading":"7.3 Intervals Based on a Normal Population Distribution","text":"Use \\(t\\) distributions.Skip “Prediction Interval Single Future Value” p. 299 end sectionThis test.","code":""},{"path":"ch.-8-tests-of-hypotheses-based-on-a-single-sample.html","id":"ch.-8-tests-of-hypotheses-based-on-a-single-sample","chapter":"Ch. 8 Tests of Hypotheses Based on a Single Sample","heading":"Ch. 8 Tests of Hypotheses Based on a Single Sample","text":"Sections covered: 8.1, 8.2, 8.3, 8.4","code":""},{"path":"ch.-8-tests-of-hypotheses-based-on-a-single-sample.html","id":"hypotheses-and-test-procedures","chapter":"Ch. 8 Tests of Hypotheses Based on a Single Sample","heading":"8.1 Hypotheses and Test Procedures","text":"Note: cover beginning section return errors hypothesis testing (beginning page 317) Section 8.2.Skip: Examples 8.1 8.4 (hypothesis testing type II error calculation small sample proportions)xkcd cartoon: “Significant” (Jelly Beans Cause Acne!)Visualizing Type Type II Errors https://shiny.rit.albany.edu/stat/betaprob/","code":""},{"path":"ch.-8-tests-of-hypotheses-based-on-a-single-sample.html","id":"z-tests-for-hypotheses-about-a-population-mean","chapter":"Ch. 8 Tests of Hypotheses Based on a Single Sample","heading":"8.2 z Tests for Hypotheses about a Population Mean","text":"Skip: calculating Type II error sample size needed two sided tests (3rd 5th formulas blue box p. 331)","code":""},{"path":"ch.-8-tests-of-hypotheses-based-on-a-single-sample.html","id":"the-one-sample-t-test","chapter":"Ch. 8 Tests of Hypotheses Based on a Single Sample","heading":"8.3 The One-Sample t Test","text":"Skip: \\(\\beta\\) Sample Size Determination (p. 338) end section","code":""},{"path":"ch.-8-tests-of-hypotheses-based-on-a-single-sample.html","id":"tests-concerning-a-population-proportion","chapter":"Ch. 8 Tests of Hypotheses Based on a Single Sample","heading":"8.4 Tests Concerning a Population Proportion","text":"Skip: \\(\\beta\\) Sample Size Determination (pp. 348-349)","code":""},{"path":"ch.-8-tests-of-hypotheses-based-on-a-single-sample.html","id":"practice-exercises-3","chapter":"Ch. 8 Tests of Hypotheses Based on a Single Sample","heading":"Practice Exercises","text":"\\(1.\\) (One sample test, Values given) wish test whether scale needs recalibrated. ’s working, 10 pound weight weigh 10 pounds. decide test weighing weight, know precisely 10 pounds, 25 times. know weights scale normally distributed independent, true standard deviation \\(\\sigma\\) = 1. sample mean (x) 9.85. conclude recalibration necessary x (, scale ) necessary (scale isn’t conclusively )?\\(α = .01​\\)\\(H_0: \\mu = 10\\)\\(H_A: \\mu \\neq 10\\)Test statistic: \\(z=\\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}}\\)Determine p-value:Since 0.453 > .05, reject null hypothesis. words, even scale perfectly calibrated (\\(\\mu = 10\\)) 45% probability get sample mean less equal 9.85 (equal greater 10.15), , true mean found. Therefore, basis results, recaliberation necessary.\\(2.\\) (One sample test, Raw values) know mean sepal length setosas (species irises) 4.8 cm. new study examines sample 50 flowers shows sample mean 5.006 cm. Conduct one-tailed hypothesis test \\(.05\\) significance level show sufficient evidence reject hypothesis mean new sample equal 4.8 cm.\\(α = .05\\)\\(H_0: \\mu = 4.8\\)\\(H_A: \\mu > 4.8\\)Use following code store 50 values sample variable called setosa. (works iris built-dataset R.)[Ans]Test statistic: \\(z=\\frac{\\bar{X} - \\mu_0}{s/\\sqrt{n}}\\)Since 6.986e-05 < 0.05 , reject null hypothesis. sufficient evidence true mean setosa sepal length greater 4.8 cm.","code":"\nz <- (9.85-10)/(1/sqrt(25))\nz## [1] -0.75\npval <- pnorm(z)*2\npval## [1] 0.4532547\nsetosa <- iris[iris$Species == \"setosa\",]\nz <- (mean(setosa$Sepal.Length)-4.8)/sqrt(var(setosa$Sepal.Length)/50)\nz## [1] 4.132433\npval <- 1- pnorm(z)\npval## [1] 1.794718e-05\n# simpler approach\n# p-values might be a bit different due to approximation of t\nt.test(setosa$Sepal.Length, alternative = \"greater\", mu = 4.8)## \n##  One Sample t-test\n## \n## data:  setosa$Sepal.Length\n## t = 4.1324, df = 49, p-value = 6.986e-05\n## alternative hypothesis: true mean is greater than 4.8\n## 95 percent confidence interval:\n##  4.922425      Inf\n## sample estimates:\n## mean of x \n##     5.006"},{"path":"ch.-9-inferences-based-on-two-samples.html","id":"ch.-9-inferences-based-on-two-samples","chapter":"Ch. 9 Inferences Based on Two Samples","heading":"Ch. 9 Inferences Based on Two Samples","text":"Sections covered: 9.1, 9.2, 9.3, 9.4","code":""},{"path":"ch.-9-inferences-based-on-two-samples.html","id":"z-tests-and-cis-for-a-difference-between-two-population-means","chapter":"Ch. 9 Inferences Based on Two Samples","heading":"9.1 \\(z\\) Tests and CI’s for a Difference Between Two Population Means","text":"(Cases 1 & 2)Skip: \\(\\beta\\) Choice Sample Size (pp. 366-367)","code":""},{"path":"ch.-9-inferences-based-on-two-samples.html","id":"r-4","chapter":"Ch. 9 Inferences Based on Two Samples","heading":"R","text":"Since aren’t given original data, R isn’t helpful , can write function reuse, :","code":"\noptions(scipen = 999) # get rid of scientific notation\n\n# this function only has to be run once per session, and then you can reuse it.\n\ndiffmeans <- function(xbar, ybar, delta0,\n                      sigma1, sigma2,\n                      m, n, type = \"twosided\") {\n  \nZ <- ((xbar - ybar) - delta0)/sqrt(((sigma1^2)/m) + ((sigma2^2)/n))\n\n\nif (type == \"twosided\") {\n  pvalue <- pnorm(-abs(Z))*2\n} else if (type == \"lowertail\") {\n  pvalue <- pnorm(Z)\n} else {\n  pvalue <- 1 - pnorm(Z)\n}\n\nprint(c(\"The p-value is\", round(pvalue, 4)))\n\n}\n\n\n# Example 9.1, p. 365\n\ndiffmeans(xbar  = 29.8, ybar  = 34.7,\n          delta0 = 0, sigma1 = 4, sigma2 = 5,\n          m = 20, n = 25, type = \"twosided\")## [1] \"The p-value is\" \"0.0003\"\n# Example 9.4, p. 368\n\n# As long as you use the correct order of parameters, you don't have to write out the names:\n\ndiffmeans(2258, 2637, -200, 1519, 1138, 663, 413, \"lowertail\")## [1] \"The p-value is\" \"0.0139\""},{"path":"ch.-9-inferences-based-on-two-samples.html","id":"the-two-sample-t-test-and-ci","chapter":"Ch. 9 Inferences Based on Two Samples","heading":"9.2 The Two-Sample \\(t\\) Test and CI","text":"(Case 3)Use: https://www.statology.org/welchs-t-test-calculator/ (choose “Enter raw data” “Enter summary data” appropriate) calculate degrees freedom.Skip: Pooled \\(t\\) Procedures (pp. 377-378)Skip: Type II Error Probabilities (pp. 378-379)Given two random samples, use t.test() different parameters carry two-sample hypothesis test.demonstration purposes, x y samples 10 numbers drawn standard normal distribution.Thus, H_0 rejected alpha = .05.t.test(), “less” indicates H_A: delta < 0. Also try using alternative = \"two.sided\" alternative = \"two.sided\" different alternative hypothesis.","code":"\nset.seed(1)\nx <- rnorm(10)\nset.seed(2)\ny <- rnorm(10)\nt.test(x, y, var.equal = TRUE, alternative = \"less\") ## \n##  Two Sample t-test\n## \n## data:  x and y\n## t = -0.19865, df = 18, p-value = 0.4224\n## alternative hypothesis: true difference in means is less than 0\n## 95 percent confidence interval:\n##      -Inf 0.610222\n## sample estimates:\n## mean of x mean of y \n## 0.1322028 0.2111516"},{"path":"ch.-9-inferences-based-on-two-samples.html","id":"analysis-of-paired-data","chapter":"Ch. 9 Inferences Based on Two Samples","heading":"9.3 Analysis of Paired Data","text":"Skip: Paired Data Two-Sample \\(t\\) Procedures (pp. 386-387)Skip: Paired Versus Unpaired Experiments (pp. 387-388)Two ways paired test:\n(continue use x y section 9.2 )\n[Method 1] Take x-y one-sample test.[Method 2] Give another parameter paired = TRUE. R, default parameter paired t.test() FALSE; set TRUE leave x y two separate inputs.’s clear give results.","code":"\nt.test(x-y, alternative = \"less\")## \n##  One Sample t-test\n## \n## data:  x - y\n## t = -0.17952, df = 9, p-value = 0.4308\n## alternative hypothesis: true mean is less than 0\n## 95 percent confidence interval:\n##       -Inf 0.7272152\n## sample estimates:\n##   mean of x \n## -0.07894886\nt.test(x, y, alternative = \"less\", paired = TRUE)## \n##  Paired t-test\n## \n## data:  x and y\n## t = -0.17952, df = 9, p-value = 0.4308\n## alternative hypothesis: true difference in means is less than 0\n## 95 percent confidence interval:\n##       -Inf 0.7272152\n## sample estimates:\n## mean of the differences \n##             -0.07894886"},{"path":"ch.-9-inferences-based-on-two-samples.html","id":"inferences-concerning-a-difference-between-population-proportions","chapter":"Ch. 9 Inferences Based on Two Samples","heading":"9.4 Inferences Concerning a Difference Between Population Proportions","text":"Skip: Type II Error Probabilities Sample Sizes (pp. 394-395)","code":""},{"path":"ch.-9-inferences-based-on-two-samples.html","id":"r-5","chapter":"Ch. 9 Inferences Based on Two Samples","heading":"R","text":"/B Testing question class:","code":"\nclicks <- c(25, 20)\npeople <- c(100, 100)\nprop.test(clicks, people, correct = FALSE)## \n##  2-sample test for equality of proportions without continuity\n##  correction\n## \n## data:  clicks out of people\n## X-squared = 0.71685, df = 1, p-value = 0.3972\n## alternative hypothesis: two.sided\n## 95 percent confidence interval:\n##  -0.06553817  0.16553817\n## sample estimates:\n## prop 1 prop 2 \n##   0.25   0.20"},{"path":"ch.-2-conditional-probability.html","id":"ch.-2-conditional-probability","chapter":"Ch. 2 Conditional Probability","heading":"Ch. 2 Conditional Probability","text":"Sections covered: 2.4, 2.5(Section 2.5 covered earlier; now ’re adding definition independence terms conditional probability p. 85: “Two events B independent P(|B) = P() dependent otherwise.”)","code":""},{"path":"ch.-2-conditional-probability.html","id":"resources","chapter":"Ch. 2 Conditional Probability","heading":"Resources","text":"Extra practice problems, Bayes Theorem(Posted Twitter response Bill Gates’ provocative comment ’d rather encounter shark mosquito wild.)Intuitive (Short) Explanation Bayes’ Theorem","code":""},{"path":"ch.-5-joint-probability.html","id":"ch.-5-joint-probability","chapter":"Ch. 5 Joint Probability","heading":"Ch. 5 Joint Probability","text":"Sections covered: 5.1, 5.2","code":""},{"path":"ch.-5-joint-probability.html","id":"jointly-distributed-random-variables","chapter":"Ch. 5 Joint Probability","heading":"5.1 Jointly Distributed Random Variables","text":"Skip everything “Two Discrete Random Variables” pp. 199-200","code":""},{"path":"ch.-5-joint-probability.html","id":"expected-values-covariance-and-correlation","chapter":"Ch. 5 Joint Probability","heading":"5.2 Expected Values, Covariance, and Correlation","text":"Skip everything “Covariance” pp. 214-215 “Correlation” pp. 216-218(sections, skip double integrals)Click anywhere graph add points. correlation coefficient calculated.\ncorrelation coefficient (r) measure linear relationship\ntwo variables x y. get sense connection \nappearance points – (x,y) pairs – scatterplot value r,\nclick anywhere graph add points. remove points, click Remove\npoints button mouseover points.\n\n Add points\n Remove points\n\nTwo points needed calculate r.\n","code":""},{"path":"ch.-5-joint-probability.html","id":"resources-1","chapter":"Ch. 5 Joint Probability","heading":"Resources","text":"Correlation Covariance Visualizationhttps://shiny.rit.albany.edu/stat/rectangles/","code":""},{"path":"ch.-12-linear-regression.html","id":"ch.-12-linear-regression","chapter":"Ch. 12 Linear Regression","heading":"Ch. 12 Linear Regression","text":"Sections covered: 12.1, 12.2, 12.5","code":""},{"path":"ch.-12-linear-regression.html","id":"the-simple-linear-regression-model","chapter":"Ch. 12 Linear Regression","heading":"12.1 The Simple Linear Regression Model","text":"","code":""},{"path":"ch.-12-linear-regression.html","id":"estimating-model-parameters","chapter":"Ch. 12 Linear Regression","heading":"12.2 Estimating Model Parameters","text":"","code":""},{"path":"ch.-12-linear-regression.html","id":"resources-2","chapter":"Ch. 12 Linear Regression","heading":"Resources","text":"Interactive Visualization: Linear Regression Try fitting least squares line set random data check answer (another one).Video: Regression : regression? | SSE, SSR, SST | R-squared | Errors (ε vs. e) [contributed Lance J.]","code":""},{"path":"ch.-12-linear-regression.html","id":"r-6","chapter":"Ch. 12 Linear Regression","heading":"R","text":"Calculating slope intercept sample (x, y) pairs (p. 498 formulas)Predicted values:Residuals:SSE, SSRThe first row “Sum Sq” SSR, second row “Sum Sq” SSE:SSE = 0.2624565SSR = 2.2946864SST = SSE + SSR = 0.2624565 +\n2.2946864 = 2.5571Coefficient determination \\(r^2\\)(simply):(See section 12.5)","code":"\n# Example 12.8, p. 503\nx <- c(12, 30, 36, 40, 45, 57, 62, 67, 71, 78, 93, 94, 100, 105)\ny <- c(3.3, 3.2, 3.4, 3, 2.8, 2.9, 2.7, 2.6, 2.5, 2.6, 2.2, 2, 2.3, 2.1)\nlm(y ~ x)  #lm = linear model## \n## Call:\n## lm(formula = y ~ x)\n## \n## Coefficients:\n## (Intercept)            x  \n##     3.62091     -0.01471\nmod <- lm(y~x)\nround(mod$fitted.values, 2)##    1    2    3    4    5    6    7    8    9   10   11   12   13   14 \n## 3.44 3.18 3.09 3.03 2.96 2.78 2.71 2.64 2.58 2.47 2.25 2.24 2.15 2.08\nround(mod$residuals, 2)##     1     2     3     4     5     6     7     8     9    10    11    12    13 \n## -0.14  0.02  0.31 -0.03 -0.16  0.12 -0.01 -0.04 -0.08  0.13 -0.05 -0.24  0.15 \n##    14 \n##  0.02\nanova(mod)  # anova = analysis of variance## Analysis of Variance Table\n## \n## Response: y\n##           Df  Sum Sq Mean Sq F value       Pr(>F)    \n## x          1 2.29469 2.29469  104.92 0.0000002762 ***\n## Residuals 12 0.26246 0.02187                         \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n# Example 12.4, 12.9\nx <- c(132, 129, 120, 113.2, 105, 92, 84, 83.2, 88.4, 59, 80, 81.5, 71, 69.2)\ny <- c(46, 48, 51, 52.1, 54, 52, 59, 58.7, 61.6, 64, 61.4, 54.6, 58.8, 58)\n\nmod <- lm(y ~ x)\n\nSSE <- anova(mod)$`Sum Sq`[1]\nSST <- anova(mod)$`Sum Sq`[1] + anova(mod)$`Sum Sq`[2]\n1 - (SSE/SST)## [1] 0.2092398\ncor(x,y)^2## [1] 0.7907602"},{"path":"ch.-12-linear-regression.html","id":"correlation","chapter":"Ch. 12 Linear Regression","heading":"12.5 Correlation","text":"Skip: “Inferences Population Correlation Coefficient” (p. 530) end section.","code":""},{"path":"ch.-12-linear-regression.html","id":"resources-3","chapter":"Ch. 12 Linear Regression","heading":"Resources","text":"Interactive visualization: Correlation Coefficient (add remove points)Interactive visualization: Interpreting Correlations [contributed Dario G.]","code":""},{"path":"ch.-12-linear-regression.html","id":"r-7","chapter":"Ch. 12 Linear Regression","heading":"R","text":"Sample correlation coefficient \\(r\\)","code":"\n# Example 12.15, p. 528\nx <- c(2.4, 3.4, 4.6, 3.7, 2.2, 3.3, 4.0, 2.1)\ny <- c(1.33, 2.12, 1.80, 1.65, 2.00, 1.76, 2.11, 1.63)\n\ncor(x,y)## [1] 0.3472602"},{"path":"ch.-12-linear-regression.html","id":"practice-exercises-4","chapter":"Ch. 12 Linear Regression","heading":"Practice Exercises","text":"(Least squares line) Researchers employed least squares analysis studying \\(Y=\\) porosity (%) related \\(X=\\) unit weight (pcf) concrete specimens. Consider following representative data:(Textbook 12.17)Obtain equation estimated regression line.\\(y = 118.91 - 0.9047x\\)Calculate residuals corresponding first two observations.alternatively, use R calculatorCalculate point estimate \\(\\sigma\\).proportion observed variation porosity can attributed approximate linear relationship unit weight porosity?Calculate SSE SST.alternatively, use R calculator. Notice results produced.","code":"\nx <- c(99.0, 101.1, 102.7, 103.0, 105.4, 107.0, 108.7, 110.8, 112.1, 112.4, 113.6, 113.8, 115.1, 115.4, 120.0)\ny <- c(28.8, 27.9, 27.0, 25.2, 22.8, 21.5, 20.9, 19.6, 17.1, 18.9, 16.0, 16.7, 13.0, 13.6, 10.8)\nlm(y~x)## \n## Call:\n## lm(formula = y ~ x)\n## \n## Coefficients:\n## (Intercept)            x  \n##    118.9099      -0.9047\nmod <- lm(y~x)\nround(mod$residuals, 2)##     1     2     3     4     5     6     7     8     9    10    11    12    13 \n## -0.54  0.46  1.01 -0.52 -0.75 -0.60  0.33  0.93 -0.39  1.68 -0.13  0.75 -1.78 \n##    14    15 \n## -0.90  0.46\npred <- 118.9099 - 0.9047*x\nres <- y - pred\nres[1]## [1] -0.5446\nres[2]## [1] 0.45527\nsig2 <- sum((res)^2)/(length(x)-2)\nsqrt(sig2)## [1] 0.938042\ncor(x, y)^2## [1] 0.9738874\nanova(mod) # analsis of variance## Analysis of Variance Table\n## \n## Response: y\n##           Df Sum Sq Mean Sq F value           Pr(>F)    \n## x          1 426.62  426.62  484.84 0.00000000001125 ***\n## Residuals 13  11.44    0.88                             \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nSSE <- anova(mod)$`Sum Sq`[1]\nSST <- anova(mod)$`Sum Sq`[1] + anova(mod)$`Sum Sq`[2]\nc(SSE, SST)## [1] 426.6185 438.0573\nSSE1 <- sum((mod$residual)^2)\nSST1 <- sum((y-mean(y))^2)\nSSR1 <- sum((mod$fitted.values - mean(y))^2)\nc(SSE1, SST1, SSE1+SSR1)## [1]  11.43883 438.05733 438.05733"}]
