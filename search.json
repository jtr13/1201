[{"path":"index.html","id":"info","chapter":"1201.info","heading":"1201.info","text":"site contains supplemental materials Stat 1201, mainly: 1) clarifications sections cover textbook (Devore, Probability Statistics Engineering Sciences 9th edition), 2) R code, 3) links helpful resources online. way substitute materials available CourseWorks.find additional online resources helpful class, please create issue send email ’ll add resource. Let know well find typos mistakes.Note ’re encouraged look ahead, sure circle back sections ’re covered class since content may added modified slightly.","code":""},{"path":"index.html","id":"general-study-tips","chapter":"1201.info","heading":"General study tips","text":"website book Make Stick offers summary experimentally tested study strategies. tl;dr :working problems better reviewing notes / textbookworking problems better reviewing notes / textbookdoing mixed reviews better focusing one type problem timedoing mixed reviews better focusing one type problem timelearning hard work; seems easy study strategy might effectivelearning hard work; seems easy study strategy might effectivemaking mistakes learning useful strategy (don’t wait ’ve mastered examples try problem)making mistakes learning useful strategy (don’t wait ’ve mastered examples try problem)’ve likely heard lot ideas , ’s worth really thinking putting practice.advice:’re reading textbook working problem set, keep list questions. Challenge thinking problem differ changed setup.’re reading textbook working problem set, keep list questions. Challenge thinking problem differ changed setup.Try creating questions solving .Try creating questions solving .Try solving problems multiple ways.Try solving problems multiple ways.Learn variety sources: class, textbook, Cartoon Guide, etc. find differences, ask.Learn variety sources: class, textbook, Cartoon Guide, etc. find differences, ask.","code":""},{"path":"index.html","id":"license","chapter":"1201.info","heading":"License","text":"work licensed Creative Commons Attribution-ShareAlike 4.0 International License.","code":""},{"path":"getting-started-with-r.html","id":"getting-started-with-r","chapter":"Getting Started with R","heading":"Getting Started with R","text":"","code":""},{"path":"getting-started-with-r.html","id":"using-r-without-installing-it","chapter":"Getting Started with R","heading":"Using R without installing it","text":"https://rdrr.io/snippets/bare minimum:can create vectors numbers using format:can use R functions find numerical graphical summaries vectors (collections numbers):","code":"\nx <- c(10, 12, 15, 20, 21, 22, 35, 45, 50)      # click to copy --> \nmean(x)## [1] 25.55556\nmedian(x)## [1] 21\nsd(x)## [1] 14.43183\nfivenum(x)## [1] 10 15 21 35 50\nstem(x)## \n##   The decimal point is 1 digit(s) to the right of the |\n## \n##   1 | 025\n##   2 | 012\n##   3 | 5\n##   4 | 5\n##   5 | 0\nhist(x)\nboxplot(x)"},{"path":"getting-started-with-r.html","id":"installing-r","chapter":"Getting Started with R","heading":"Installing R","text":"need install two applications: R RStudio:R – programming language – available :https://cran.r-project.orgRStudio – integrated development environment (IDE) makes much easier use R. optional highly recommended. app open use R. Choose free version RStudio Desktop:https://www.rstudio.com/products/rstudio/download/#download","code":""},{"path":"getting-started-with-r.html","id":"getting-started-with-r-working-in-the-console","chapter":"Getting Started with R","heading":"Getting Started with R: Working in the Console","text":"first step getting started getting comfortable working RStudio console. works like calculator sense work saved. following:","code":""},{"path":"getting-started-with-r.html","id":"watch-the-video","chapter":"Getting Started with R","heading":"Watch the video","text":"","code":""},{"path":"getting-started-with-r.html","id":"quick-review-of-material-covered-in-the-video-plus-additional-examples","chapter":"Getting Started with R","heading":"Quick review of material covered in the video, plus additional examples","text":"Working console pane similar using calculator: line code executed press enter. Note work saved approach.Assigning variableDrawing stem leaf plotBasic operations:Working vectors:","code":"\n3 + 4## [1] 7\n3 - 4## [1] -1\n3 * 4## [1] 12\n3 / 4## [1] 0.75\n3^4## [1] 81\nsqrt(3)## [1] 1.732051\nx <- 1:5\nx## [1] 1 2 3 4 5\nx + 10## [1] 11 12 13 14 15\nx^2## [1]  1  4  9 16 25\nsum(x)## [1] 15"},{"path":"getting-started-with-r.html","id":"additional-resources","chapter":"Getting Started with R","heading":"Additional resources","text":"See examples Chapter 1 Introduction R","code":""},{"path":"getting-started-with-r.html","id":"creating-graphs-saving-your-work","chapter":"Getting Started with R","heading":"Creating Graphs, Saving your work","text":"Video","code":""},{"path":"getting-started-with-r.html","id":"saving-code-as-an-.r-file","chapter":"Getting Started with R","heading":"Saving code as an .R file","text":"(Also covered video )Saving method saves code, output. two methods creating .html documents contain code output:","code":""},{"path":"getting-started-with-r.html","id":"convert-.r-file-to-.html","chapter":"Getting Started with R","heading":"Convert .R file to .html","text":"(Also covered video )","code":""},{"path":"getting-started-with-r.html","id":"reading-files","chapter":"Getting Started with R","heading":"Reading files","text":"easiest way read data textbook exercises read directly following URL follows:(Full URL: https://raw.githubusercontent.com/jtr13/1201/main/Devore9e_Final_Datasets/CSV/CH01/ex01-63.csv)Note data data frame:convert vector use:Now can use functions described :","code":"\ndata <- read.csv(\"https://raw.githubusercontent.com/jtr13/1201/main/Devore9e_Final_Datasets/CSV/CH01/ex01-63.csv\")\nhead(data)##   noise\n## 1  55.3\n## 2  55.3\n## 3  55.3\n## 4  55.9\n## 5  55.9\n## 6  55.9\nnoise <- data$noise\nboxplot(noise, horizontal = TRUE)"},{"path":"ch.-1-descriptive-statistics.html","id":"ch.-1-descriptive-statistics","chapter":"Ch. 1 Descriptive Statistics","heading":"Ch. 1 Descriptive Statistics","text":"Sections covered: (skim 1.1)","code":""},{"path":"ch.-1-descriptive-statistics.html","id":"pictorial-and-tabular-methods-in-descriptive-statistics","chapter":"Ch. 1 Descriptive Statistics","heading":"1.2 Pictorial and Tabular Methods in Descriptive Statistics","text":"Skip: Example 1.7, p. 15 (double-digit leaves)Skip: “Dotplots,” pp. 15-16","code":""},{"path":"ch.-1-descriptive-statistics.html","id":"stem-and-leaf-plots","chapter":"Ch. 1 Descriptive Statistics","heading":"Stem-and-leaf plots","text":"Ex: following listing prices (thousands $) one-bedroom apartments Morningside Heights 2016:\n379, 425, 450, 450, 499, 529, 535, 535, 545, 599, 665, 675, 699, 699, 725, 725, 745, 799Draw stem leaf plot data:Create new variable (’ll call “prices”). Note: use syntax <- c() generate new vectors.Draw stem leaf plotThe scale parameter change number rows factor specified:","code":"\nprices <- c(379, 425, 450, 450, 499, 529, 535, 535, 545, 599, 665,\n            675, 699, 699, 725, 725, 745, 799)\nprices <- c(379, 425, 450, 450, 499, 529, 535, 535, 545, 599, 665,\n            675, 699, 699, 725, 725, 745, 799)\nstem(prices)## \n##   The decimal point is 2 digit(s) to the right of the |\n## \n##   3 | 8\n##   4 | 355\n##   5 | 03445\n##   6 | 078\n##   7 | 00335\n##   8 | 0\nstem(prices, scale = 2)## \n##   The decimal point is 2 digit(s) to the right of the |\n## \n##   3 | 8\n##   4 | 3\n##   4 | 55\n##   5 | 0344\n##   5 | 5\n##   6 | 0\n##   6 | 78\n##   7 | 0033\n##   7 | 5\n##   8 | 0\nstem(prices, scale = .5)## \n##   The decimal point is 2 digit(s) to the right of the |\n## \n##   2 | 8\n##   4 | 35503445\n##   6 | 07800335\n##   8 | 0"},{"path":"ch.-1-descriptive-statistics.html","id":"frequency-histogram","chapter":"Ch. 1 Descriptive Statistics","heading":"Frequency histogram","text":"want create frequency histogram data use following:Note: histograms drawn unbinned data. R binning process drawing histogram. means program chooses size bins .add specific bin sizes colors histogram, can use following syntax:","code":"\nprices <- c(379, 425, 450, 450, 499, 529, 535, 535, 545, 599, 665,\n            675, 699, 699, 725, 725, 745, 799)\n\nhist(prices)\nprices <- c(379, 425, 450, 450, 499, 529, 535, 535, 545, 599, 665,\n            675, 699, 699, 725, 725, 745, 799)\nhist(prices, breaks = c(300, 400, 500, 600, 700, 800),\n     col = \"lightblue\")"},{"path":"ch.-1-descriptive-statistics.html","id":"density-histogram","chapter":"Ch. 1 Descriptive Statistics","heading":"Density histogram","text":"use almost identical syntax generate density histograms, add parameter freq=FALSE – , frequency histogram.(las = 1 makes labels horizontal.)","code":"\nprices <- c(379, 425, 450, 450, 499, 529, 535, 535, 545, 599, 665,\n            675, 699, 699, 725, 725, 745, 799)\n\nhist(prices, freq = FALSE, \n     breaks = c(300, 400, 500, 600, 700, 800),\n     col = \"lightblue\", las = 1)"},{"path":"ch.-1-descriptive-statistics.html","id":"measures-of-location","chapter":"Ch. 1 Descriptive Statistics","heading":"1.3 Measures of location","text":"Skip: Example 1.16, p. 33 (trimmed mean)Skip: “Categorical Data Sample Proportions,” p. 34 (’ll return topic later.)Consider dataset (prices). find mean, median, quartiles, trimmed mean, use following syntax:","code":"\nprices <- c(379, 425, 450, 450, 499, 529, 535, 535, 545, 599, 665,\n            675, 699, 699, 725, 725, 745, 799)\n\nmean(prices)## [1] 593.2222\nmedian(prices)## [1] 572\n## quartiles\nquantile(prices)##    0%   25%   50%   75%  100% \n## 379.0 506.5 572.0 699.0 799.0\n## trimmed mean\nmean(prices, trim = .1) ## 10% trimmed off each end## [1] 593.75"},{"path":"ch.-1-descriptive-statistics.html","id":"measures-of-variability","chapter":"Ch. 1 Descriptive Statistics","heading":"1.4 Measures of variability","text":"Skip: extreme outliers (p. 42)define outliers boxplots observations 1.5 times fourth spread closest fourth. may indicated either solid open circle (contrast book uses one mild outliers extreme outliers.)","code":""},{"path":"ch.-1-descriptive-statistics.html","id":"numerical-summaries","chapter":"Ch. 1 Descriptive Statistics","heading":"Numerical summaries","text":"Sample variance:Sample standard deviation:Five number summary(min, lower-hinge, median, upper-hinge, max)want generate horizontal boxplot, use following","code":"\nprices <- c(379, 425, 450, 450, 499, 529, 535, 535, 545, 599, 665,\n            675, 699, 699, 725, 725, 745, 799)\n\nvar(prices)## [1] 15981.48\nsqrt(var(prices))## [1] 126.4179\nsd(prices)## [1] 126.4179\nfivenum(prices)## [1] 379 499 572 699 799"},{"path":"ch.-1-descriptive-statistics.html","id":"boxplots","chapter":"Ch. 1 Descriptive Statistics","heading":"Boxplots","text":"Comparitive boxplotsA simple means create multiple boxplots list vectors wish display. Note label boxplots, use names =.","code":"\nprices <- c(379, 425, 450, 450, 499, 529, 535, 535, 545,\n            599, 665, 675, 699, 699, 725, 725, 745, 799)\n\nboxplot(prices)\nboxplot(prices, horizontal = TRUE)\nPTSD <- c(10, 20, 25, 28, 31, 35, 37, 38, 38, 39, 39, 42, 46)\n\nHealthy <- c(23, 39, 40, 41, 43, 47, 51, 58, 63, 66, 67, 69, 72)\n\nboxplot(PTSD, Healthy, names = c(\"PTSD\", \"Healthy\"), horizontal = TRUE)"},{"path":"ch.-1-descriptive-statistics.html","id":"practice-exercises","chapter":"Ch. 1 Descriptive Statistics","heading":"Practice Exercises","text":"Using built-dataset ToothGrowth R, visualize data comment effectiveness different functions context.[Ans] ","code":"\n# The first 5 rows of the data\nhead(ToothGrowth, 5)##    len supp dose\n## 1  4.2   VC  0.5\n## 2 11.5   VC  0.5\n## 3  7.3   VC  0.5\n## 4  5.8   VC  0.5\n## 5  6.4   VC  0.5\n# Five number summary\nfivenum(ToothGrowth$len)## [1]  4.20 12.55 19.25 25.35 33.90\n# Boxplot \n# '$' extracts the column by name\nboxplot(ToothGrowth$len) \n# Stem-and-leaf Plot\nstem(ToothGrowth$len)## \n##   The decimal point is 1 digit(s) to the right of the |\n## \n##   0 | 4\n##   0 | 5667789\n##   1 | 00001124\n##   1 | 55555677777899\n##   2 | 001222333344\n##   2 | 55566666667779\n##   3 | 0134\n# Histogram\nh <- hist(ToothGrowth$len)\n# Cumulative Histogram\nh$counts <- cumsum(h$counts)\nplot(h)"},{"path":"ch.-1-descriptive-statistics.html","id":"summary-of-r-functions","chapter":"Ch. 1 Descriptive Statistics","heading":"Summary of R functions","text":"head(): directly see dataset looks; useful dataset large ’s difficult display rows columns together.fivenum(): returns minimum value, lower fourth, median, upper fourth, maximum valueboxplot(): visualizes five number summary plus outliers. (’s clear ToothGrowth data skewed.)stem(): compares number data points fall different bins. (can see values 20 29.)hist(): draws histogram – values grouped binscumsum(): takes vector returns cumulative sums","code":""},{"path":"ch.-2-probability.html","id":"ch.-2-probability","chapter":"Ch. 2 Probability","heading":"Ch. 2 Probability","text":"Sections covered: 2.1, 2.2, 2.3, 2.5(2.4 covered later semester)","code":""},{"path":"ch.-2-probability.html","id":"sample-spaces-and-events","chapter":"Ch. 2 Probability","heading":"2.1 Sample Spaces and Events","text":"","code":""},{"path":"ch.-2-probability.html","id":"humor","chapter":"Ch. 2 Probability","heading":"Humor","text":"Source: https://twitter.com/bcrypt/status/1074415553266122752/photo/1","code":""},{"path":"ch.-2-probability.html","id":"axioms-interpretations-and-properties-of-probability","chapter":"Ch. 2 Probability","heading":"2.2 Axioms, Interpretations, and Properties of Probability","text":"","code":""},{"path":"ch.-2-probability.html","id":"counting-techniques","chapter":"Ch. 2 Probability","heading":"2.3 Counting Techniques","text":"","code":""},{"path":"ch.-2-probability.html","id":"r","chapter":"Ch. 2 Probability","heading":"R","text":"FactorialCombinations“5 choose 2” = choose 2 items 5PermutationsThere built-function calculate permutations. can multiply number combinations k!.Ex. Number permutations size 2 can formed 5 distinct items:can create function :","code":"\nfactorial(5)## [1] 120\nchoose(5, 2)## [1] 10\nchoose(5,2)*factorial(2)## [1] 20\nperm <- function(n, k) {choose(n,k)*factorial(k)}\n\nperm(5,2)## [1] 20"},{"path":"ch.-2-probability.html","id":"independence","chapter":"Ch. 2 Probability","heading":"2.5 Independence","text":"Skip everything “Multiplication Rule” p. 86 (return conditional probability later semester)","code":""},{"path":"ch.-3-discrete-distributions.html","id":"ch.-3-discrete-distributions","chapter":"Ch. 3 Discrete Distributions","heading":"Ch. 3 Discrete Distributions","text":"Sections covered: 3.1 - 3.6Skip: “Poisson Distribution Limit” (pp. 132-33) “Poisson Process” (pp. 134-135)direct way R calculate mean variance distribution given pmf. However can use R make calculations simpler.","code":""},{"path":"ch.-3-discrete-distributions.html","id":"expected-value","chapter":"Ch. 3 Discrete Distributions","heading":"3.3 Expected value","text":"","code":"\nx <- 1:5\nx## [1] 1 2 3 4 5\npx <- c(.1, .15, .2, .25, .3)\npx## [1] 0.10 0.15 0.20 0.25 0.30\nx*px## [1] 0.1 0.3 0.6 1.0 1.5\nsum(x*px)    # E(X)## [1] 3.5"},{"path":"ch.-3-discrete-distributions.html","id":"variance","chapter":"Ch. 3 Discrete Distributions","heading":"3.3 Variance","text":"","code":"\nx - 3.5## [1] -2.5 -1.5 -0.5  0.5  1.5\n(x - 3.5)^2## [1] 6.25 2.25 0.25 0.25 2.25\n((x - 3.5)^2)*px## [1] 0.6250 0.3375 0.0500 0.0625 0.6750\nsum(((x - 3.5)^2)*px)   # V(X)## [1] 1.75"},{"path":"ch.-3-discrete-distributions.html","id":"variance-alternative-method","chapter":"Ch. 3 Discrete Distributions","heading":"3.3 Variance (alternative method)","text":"","code":"\nx## [1] 1 2 3 4 5\npx## [1] 0.10 0.15 0.20 0.25 0.30\nx^2## [1]  1  4  9 16 25\n(x^2)*px## [1] 0.1 0.6 1.8 4.0 7.5\nsum((x^2)*px)  # E(X^2)## [1] 14\n14-3.5^2     # E(X^2) - [E(X)]^2## [1] 1.75"},{"path":"ch.-3-discrete-distributions.html","id":"binominal-theorem","chapter":"Ch. 3 Discrete Distributions","heading":"3.4 Binominal Theorem","text":"p. 121 Using binomial tables cumulative distribution function (cdf) optional; may use R (see ) www.stattrek.com instead.tests need calculate values. can leave answers summations, example:\\(\\Sigma_{x=0}^6 \\left(\\begin{array}{c}12\\\\ x\\end{array}\\right)(.3^x)(.7^{12-x})\\)","code":""},{"path":"ch.-3-discrete-distributions.html","id":"r-1","chapter":"Ch. 3 Discrete Distributions","heading":"R","text":"Probability mass function (pmf)\\(P(X = x)\\)Direct methodCumulative distribution function (cdf)\\(P(X \\leq x)\\)Find \\(P(2 \\leq X \\leq 4)\\) given \\(p = .7, n = 15\\)(Using pmf instead:)Graphing binomial pmf:ex. \\(p = .7, n = 10\\)","code":"\nchoose(8, 3)    # \"8 choose 3\"## [1] 56\n56*.6^3*.4^5     # P(X = 3) given n = 8, p = .6## [1] 0.123863\ndbinom(3, 8, .6)     # P(X = 3) given n = 8, p = .6## [1] 0.123863\npbinom(4, 15, .7) - pbinom(1, 15, .7)## [1] 0.0006717175\ndbinom(2, 15, .7) + dbinom(3, 15, .7) + dbinom(4, 15, .7)## [1] 0.0006717175\npx <- dbinom(0:10, 10, .7)\n# adding las = 1 turns the y-axis tick mark labels horizontal, which are easier to read\nbarplot(px, names.arg = 0:10, las = 1, col = \"lightblue\")"},{"path":"ch.-3-discrete-distributions.html","id":"hypergeometric","chapter":"Ch. 3 Discrete Distributions","heading":"3.5 Hypergeometric","text":"Note notation R uses different Devore textbook:Example (p. 127)Devore: h(x; n, M, N)P(X = 2) = h(2; 10, 5, 25) –>","code":"\ndhyper(x = 2, m = 5, n = 20, k = 10)## [1] 0.3853755"},{"path":"ch.-3-discrete-distributions.html","id":"poisson","chapter":"Ch. 3 Discrete Distributions","heading":"3.6 Poisson","text":"Example (p. 132)p(3;2) =F(3;2) =","code":"\ndpois(3,2)## [1] 0.180447\nppois(3, 2)## [1] 0.8571235"},{"path":"ch.-3-discrete-distributions.html","id":"practice-exercises-1","chapter":"Ch. 3 Discrete Distributions","heading":"Practice Exercises","text":"(Binomial) Suppose probability car accident involving single vehicle .7. 15 accidents randomly selected, probability 2 4, inclusive, involve single vehicle? (slides)(Binomial) particular telephone number used receive voice calls fax messages. Suppose 25% incoming calls involve fax messages, consider sample 25 incoming calls. probability \n6 calls involve fax message?\nExactly 6 calls involve fax message?\nleast 6 calls involve fax message?\nexpected number calls among 25 involve fax message?\nstandard deviation number among 25 calls involve fax message?\nprobability number calls among 25 involve fax transmission exceeds expected number 2 standard deviations? (Textbook 50-51)\n(Binomial) particular telephone number used receive voice calls fax messages. Suppose 25% incoming calls involve fax messages, consider sample 25 incoming calls. probability thatAt 6 calls involve fax message?6 calls involve fax message?Exactly 6 calls involve fax message?Exactly 6 calls involve fax message?least 6 calls involve fax message?least 6 calls involve fax message?expected number calls among 25 involve fax message?expected number calls among 25 involve fax message?standard deviation number among 25 calls involve fax message?standard deviation number among 25 calls involve fax message?probability number calls among 25 involve fax transmission exceeds expected number 2 standard deviations? (Textbook 50-51)probability number calls among 25 involve fax transmission exceeds expected number 2 standard deviations? (Textbook 50-51)(Hypergeometric) geologist collected 8 specimens basaltic rock 12 specimens granite. geologist instructs laboratory assistant randomly select 15 specimens analysis.\nprobability specimens one two types rock selected analysis?\nprobability number granite specimens selected analysis within 1 standard deviation mean value? (Textbook 71)\n(Hypergeometric) geologist collected 8 specimens basaltic rock 12 specimens granite. geologist instructs laboratory assistant randomly select 15 specimens analysis.probability specimens one two types rock selected analysis?probability specimens one two types rock selected analysis?probability number granite specimens selected analysis within 1 standard deviation mean value? (Textbook 71)probability number granite specimens selected analysis within 1 standard deviation mean value? (Textbook 71)(Negative Binomial) probability randomly selected box certain type cereal particular prize .2. Suppose purchase box box obtained two prizes.\nprobability purchase \\(x\\) boxes desired prize?\nprobability purchase four boxes?\nprobability purchase four boxes?\nmany boxes without desired prize expect purchase? many boxes expect purchase? (Textbook 75, homework)\n(Negative Binomial) probability randomly selected box certain type cereal particular prize .2. Suppose purchase box box obtained two prizes.probability purchase \\(x\\) boxes desired prize?probability purchase \\(x\\) boxes desired prize?probability purchase four boxes?probability purchase four boxes?probability purchase four boxes?probability purchase four boxes?many boxes without desired prize expect purchase? many boxes expect purchase? (Textbook 75, homework)many boxes without desired prize expect purchase? many boxes expect purchase? (Textbook 75, homework)Let x number boxes without prizes purchased, \\(p = {x+2-1\\choose1}(.2^2)(.8 ^x)\\)(Poisson) Suppose number drivers travel particular origin destination designated time period Poisson distribution parameter \\(\\mu = 20\\). probability number drivers \n10?\n10?\nwithin 2 standard deviations mean value?\n(Textbook 81)(Poisson) Suppose number drivers travel particular origin destination designated time period Poisson distribution parameter \\(\\mu = 20\\). probability number drivers willBe 10?10?10?10?within 2 standard deviations mean value?within 2 standard deviations mean value?(Textbook 81)","code":"\ndbinom(2, 15, .7) + dbinom(3, 15, .7) + dbinom(4, 15, .7)## [1] 0.0006717175\npbinom(4, 15, .7) - pbinom(1, 15, .7)## [1] 0.0006717175\npbinom(6, 25, .25)## [1] 0.5610981\ndbinom(6, 25, .25)## [1] 0.1828195\n1 - pbinom(5, 25, .25)## [1] 0.6217215\nE <- 25*.25\nVar <- 25*.25*.75\npbinom(floor(E+2*sqrt(Var)), 25, .25)## [1] 0.9703301\ndhyper(8, 8, 12, 15) + dhyper(3, 8, 12, 15)## [1] 0.05469556\nmean_g <- 15*12/20\nsd_g <- sqrt(20*(12/20)*(8/20))\npbinom(mean_g + sd_g, 15, 12/20)-pbinom(mean_g - sd_g, 15, 12/20)## [1] 0.8144507\ndnbinom(2, 2, .2)## [1] 0.0768\ndnbinom(2, 2, .2) + dnbinom(1, 2, .2) + dnbinom(0, 2, .2)## [1] 0.1808\n2*.8/.2## [1] 8\n# 8 boxes without desired prize, 10 boxes in total\nppois(10, 20) # a## [1] 0.01081172\ndpois(10, 20) # b1## [1] 0.005816307\n((exp(1)^-20)*(20^10))/factorial(10) # b2## [1] 0.005816307\nppois(20 + 2*sqrt(20),20) - ppois(20 - 2*sqrt(20), 20) # c## [1] 0.9442797"},{"path":"ch.-4-continuous-random-variables-and-probability-distributions.html","id":"ch.-4-continuous-random-variables-and-probability-distributions","chapter":"Ch. 4 Continuous Random Variables and Probability Distributions","heading":"Ch. 4 Continuous Random Variables and Probability Distributions","text":"Sections covered: 4.1, 4.2, 4.3, 4.4 (exponential )","code":""},{"path":"ch.-4-continuous-random-variables-and-probability-distributions.html","id":"probability-density-functions","chapter":"Ch. 4 Continuous Random Variables and Probability Distributions","heading":"4.1 Probability density functions","text":"","code":""},{"path":"ch.-4-continuous-random-variables-and-probability-distributions.html","id":"r-2","chapter":"Ch. 4 Continuous Random Variables and Probability Distributions","heading":"R","text":"Simulating uniform distributionRandomly choose one number distribution:\\(f(x) = .2\\) \\(0 \\leq x \\leq 5\\), 0 otherwise.Take average 1000 picks:Draw histogram 1000 picks:","code":"\nrunif(n = 1, min = 0, max = 5)## [1] 3.599089\nx <- runif(n = 1000, min = 0, max = 5)\nmean(x)## [1] 2.498613\nhist(x, las = 1, col = \"lightblue\")"},{"path":"ch.-4-continuous-random-variables-and-probability-distributions.html","id":"cumulative-distribution-functions-and-expected-values","chapter":"Ch. 4 Continuous Random Variables and Probability Distributions","heading":"4.2 Cumulative Distribution Functions and Expected Values","text":"Using R help calculations Example 4.7, p. 149Define function cdf (integration ):Find \\(F(1.5) - F(1)\\)","code":"\nF <- function(x) (x/8) + (3/16)*x^2\nF(1.5) - F(1)## [1] 0.296875"},{"path":"ch.-4-continuous-random-variables-and-probability-distributions.html","id":"the-normal-distribution","chapter":"Ch. 4 Continuous Random Variables and Probability Distributions","heading":"4.3 The Normal Distribution","text":"Interactive normal distribution – change \\(\\mu\\) \\(\\sigma\\) see happens.Normal table – pdf form viewing online, downloading /printingOnline normal distribution lookup – enter \\(z\\) calculate \\(F(z) = P(Z \\leq z)\\).many online normal distribution calculators. Note often given choice finding \\(P(Z \\leq z)\\), \\(P(Z \\geq z)\\), \\(P(0 \\leq Z \\leq z)\\), etc., careful. consistent normal tables textbook / class, choose \\(P(Z \\leq z)\\).Due rounding differences \\(z\\) \\(P(Z \\leq z)\\), solutions using technology vary using normal table. methods fine.","code":""},{"path":"ch.-4-continuous-random-variables-and-probability-distributions.html","id":"r-3","chapter":"Ch. 4 Continuous Random Variables and Probability Distributions","heading":"R","text":"\\(P(Z \\leq -1)\\)Unless specified otherwise, pnorm uses mean 0 standard deviation 1 (standard normal).\\(P(X \\leq 37)\\) given \\(\\mu = 40\\) \\(\\sigma = 2\\)\\(P(X > 39)\\)Find 75th percentile standard normal distribution:Find 75th percentile normally distribution population mean 40 standard deviation 2:","code":"\npnorm(-1)## [1] 0.1586553\npnorm(37, mean = 40, sd = 2)## [1] 0.0668072\npnorm((37-40)/2)## [1] 0.0668072\n1 - pnorm(39, mean = 40, sd = 2)## [1] 0.6914625\nqnorm(.75)## [1] 0.6744898\nqnorm(.75, mean = 40, sd = 2)## [1] 41.34898\n40 + qnorm(.75)*2## [1] 41.34898"},{"path":"ch.-4-continuous-random-variables-and-probability-distributions.html","id":"practice-exercises-2","chapter":"Ch. 4 Continuous Random Variables and Probability Distributions","heading":"Practice Exercises","text":"(pdf, E V) \\(X\\) continuous random variable probability distrbution \\(f(x)=.06x + .05\\) \\(0\\leq x \\leq 5\\).\nprobability \\(2\\leq x\\leq 4\\)?\nprobability \\(x = 4\\)?\nexpected value \\(X\\)?\nvariance X?\n(pdf, E V) \\(X\\) continuous random variable probability distrbution \\(f(x)=.06x + .05\\) \\(0\\leq x \\leq 5\\).probability \\(2\\leq x\\leq 4\\)?probability \\(x = 4\\)?expected value \\(X\\)?variance X?[Ans]\n. Integrating hand: \\(f(x)=.06x + .05\\), get \\(F(x) = .03x^2+.05x\\).00Integrate \\(x\\cdot f(x) = x(.06x+.05)=.06x^2+.05x\\), get \\(H(x) = .02x^3+.025x^2\\).Integrate \\(x\\cdot f(x) = x(.06x+.05)=.06x^2+.05x\\), get \\(H(x) = .02x^3+.025x^2\\).\\(V(X) = E(X^2)-[E(X)]^2\\).\nIntegrate \\(x^2\\cdot f(x) = x^2(.06x+.05)=.06x^3+.05x^2\\), get \\(G(x) = .015x^4+\\frac{.05}3x^3\\).(Standard Normal, pnorm) driver’s reaction time -traffic response brake signal can modeled normal distribution mean value 1.25 sec standard deviation .46 sec. (Textbook 4.16)\nprobability reaction time 1.00 sec 1.75 sec?\nprobability reaction time exceeds 2.00 sec?\n(Standard Normal, pnorm) driver’s reaction time -traffic response brake signal can modeled normal distribution mean value 1.25 sec standard deviation .46 sec. (Textbook 4.16)probability reaction time 1.00 sec 1.75 sec?probability reaction time 1.00 sec 1.75 sec?probability reaction time exceeds 2.00 sec?probability reaction time exceeds 2.00 sec?(Nonstandard Normal, qnorm) Data collected experiment specified initial crack\nlength propose normal distribution mean value 5.496 mm standard deviation .067 mm. model, value final crack depth exceeded .5% cracks? (Textbook 4.18)(Binom Appproximation) Suppose 25% students large public university receive financial aid. Let \\(X\\) number students random sample size 50 receive financial\naid, sothat p = .25. probability 10 students receive aid? (Textbook 4.20)","code":"\nF <- function(x) 0.03*x^2 + 0.05*x\nx <- runif(n = 1000, min = 0, max = 5)\nF(4) - F(2)## [1] 0.46\nH <- function(x) 0.02*x^3 + 0.025*x^2\nH(5)-H(0) ## [1] 3.125\nE <- H(5)-H(0)\nG <- function(x) .015*(x^4)+(.05/3)*(x^3)\nG(5)-G(0)-E^2## [1] 1.692708\npnorm((1.75-1.25)/0.46) - pnorm((1-1.25)/0.46)## [1] 0.5680717\n1 - pnorm((2-1.25)/0.46)## [1] 0.05150482\n# alternatively\npnorm(-(2-1.25)/0.46)## [1] 0.05150482\nqnorm(0.995, 5.496, .067)## [1] 5.668581\n# binom distribution calculation\npbinom(10, size = 50, prob = 0.25) ## [1] 0.2622023\n# normal approximation of binom\npnorm((10 + .5 - 50*.25)/sqrt(50*.25*.75))## [1] 0.2568146"},{"path":"ch.-4-continuous-random-variables-and-probability-distributions.html","id":"extra-practice-chapters-1---4","chapter":"Ch. 4 Continuous Random Variables and Probability Distributions","heading":"Extra Practice Chapters 1 - 4","text":"QuestionsSolutions","code":""},{"path":"ch.-5-random-samples.html","id":"ch.-5-random-samples","chapter":"Ch. 5 Random Samples","heading":"Ch. 5 Random Samples","text":"Sections covered: 5.3, 5.4, 5.5","code":""},{"path":"ch.-5-random-samples.html","id":"the-distribution-of-the-sample-mean","chapter":"Ch. 5 Random Samples","heading":"5.4 The Distribution of the Sample Mean","text":"Central Limit Theorem visualization: http://mfviz.com/central-limit/","code":""},{"path":"ch.-5-random-samples.html","id":"the-distribution-of-a-linear-combination","chapter":"Ch. 5 Random Samples","heading":"5.5 The Distribution of a Linear Combination","text":"Skip (now): formula (5.11) – variance linear combination assuming independence \\(X_i\\)’s.","code":""},{"path":"ch.-6-point-estimation.html","id":"ch.-6-point-estimation","chapter":"Ch. 6 Point Estimation","heading":"Ch. 6 Point Estimation","text":"Sections covered: 6.1","code":""},{"path":"ch.-6-point-estimation.html","id":"some-general-concepts-of-point-estimation","chapter":"Ch. 6 Point Estimation","heading":"6.1 Some General Concepts of Point Estimation","text":"Skip everything beginning “Complications” p. 257","code":""},{"path":"ch.-7-statistical-intervals-based-on-a-single-sample.html","id":"ch.-7-statistical-intervals-based-on-a-single-sample","chapter":"Ch. 7 Statistical Intervals Based on a Single Sample","heading":"Ch. 7 Statistical Intervals Based on a Single Sample","text":"Sections covered: 7.1, 7.2, 7.3","code":""},{"path":"ch.-7-statistical-intervals-based-on-a-single-sample.html","id":"basic-properties-of-confidence-intervals","chapter":"Ch. 7 Statistical Intervals Based on a Single Sample","heading":"7.1 Basic Properties of Confidence Intervals","text":"Skip: “Deriving Confidence Interval”, pp. 282-284; “Bootstrap Confidence Intervals”, p. 284","code":""},{"path":"ch.-7-statistical-intervals-based-on-a-single-sample.html","id":"large-sample-confidence-intervals-for-a-population-mean-and-proportion","chapter":"Ch. 7 Statistical Intervals Based on a Single Sample","heading":"7.2 Large-Sample Confidence Intervals for a Population Mean and Proportion","text":"may use: \\(\\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}\\hat{q}}{n}}\\), rather formula (7.10) blue box p. 289 large sample confidence intervals proportions, skip p. 290You may use method class \\(n = \\frac{4z^2\\hat{p}\\hat{q}}{w^2}\\) minimum \\(n\\) needed ensure particular confidence interval width proportions, rather formula (7.12) – appear p. 291. noted Example 7.9 p. 291, easier formula gives slightly different answer (385 instead 381).Additional textbook material CI proportions“Hear Margin Error Plus Minus 3 Percent, Think 7 Instead”, New York Times, Oct 5, 2016.","code":""},{"path":"ch.-7-statistical-intervals-based-on-a-single-sample.html","id":"intervals-based-on-a-normal-population-distribution","chapter":"Ch. 7 Statistical Intervals Based on a Single Sample","heading":"7.3 Intervals Based on a Normal Population Distribution","text":"Use \\(t\\) distributions.Skip “Prediction Interval Single Future Value” p. 299 end section.","code":""},{"path":"ch.-8-tests-of-hypotheses-based-on-a-single-sample.html","id":"ch.-8-tests-of-hypotheses-based-on-a-single-sample","chapter":"Ch. 8 Tests of Hypotheses Based on a Single Sample","heading":"Ch. 8 Tests of Hypotheses Based on a Single Sample","text":"Sections covered: 8.1, 8.2, 8.3, 8.4, 8.5","code":""},{"path":"ch.-8-tests-of-hypotheses-based-on-a-single-sample.html","id":"hypotheses-and-test-procedures","chapter":"Ch. 8 Tests of Hypotheses Based on a Single Sample","heading":"8.1 Hypotheses and Test Procedures","text":"Note: cover beginning section return errors hypothesis testing (beginning page 317) Section 8.2.Skip: Examples 8.1 8.4 (hypothesis testing type II error calculation small sample proportions)xkcd cartoon: “Significant” (Jelly Beans Cause Acne!)","code":""},{"path":"ch.-8-tests-of-hypotheses-based-on-a-single-sample.html","id":"z-tests-for-hypotheses-about-a-population-mean","chapter":"Ch. 8 Tests of Hypotheses Based on a Single Sample","heading":"8.2 z Tests for Hypotheses about a Population Mean","text":"Skip: calculating Type II error sample size needed two sided tests (3rd 5th formulas blue box p. 331)Interactive resource:\nVisualize Type /II errors: One-sample Test Means (Z test)","code":""},{"path":"ch.-8-tests-of-hypotheses-based-on-a-single-sample.html","id":"the-one-sample-t-test","chapter":"Ch. 8 Tests of Hypotheses Based on a Single Sample","heading":"8.3 The One-Sample t Test","text":"Skip: \\(\\beta\\) Sample Size Determination (p. 338) end section","code":""},{"path":"ch.-8-tests-of-hypotheses-based-on-a-single-sample.html","id":"tests-concerning-a-population-proportion","chapter":"Ch. 8 Tests of Hypotheses Based on a Single Sample","heading":"8.4 Tests Concerning a Population Proportion","text":"Skip: \\(\\beta\\) Sample Size Determination (pp. 348-349)","code":""},{"path":"ch.-8-tests-of-hypotheses-based-on-a-single-sample.html","id":"further-aspects-of-hypothesis-testing","chapter":"Ch. 8 Tests of Hypotheses Based on a Single Sample","heading":"8.5 Further Aspects of Hypothesis Testing","text":"Skip: Likelihood Ratio Principle (pp. 355-356)","code":""},{"path":"ch.-8-tests-of-hypotheses-based-on-a-single-sample.html","id":"practice-exercises-3","chapter":"Ch. 8 Tests of Hypotheses Based on a Single Sample","heading":"Practice Exercises","text":"\\(1.\\) (One sample test, Values given) wish test whether scale needs recalibrated. ’s working, 10 pound weight weigh 10 pounds. decide test weighing weight, know precisely 10 pounds, 25 times. know weights scale normally distributed independent, true standard deviation \\(\\sigma\\) = 1. sample mean (x) 9.85. conclude recalibration necessary x (, scale ) necessary (scale isn’t conclusively )?\\(α = .01​\\)\\(H_0: \\mu = 10\\)\\(H_A: \\mu \\neq 10\\)Test statistic: \\(z=\\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}}\\)Determine p-value:Since 0.453 > .05, reject null hypothesis. words, even scale perfectly calibrated (\\(\\mu = 10\\)) 45% probability get sample mean less equal 9.85 (equal greater 10.15), , true mean found. Therefore, basis results, recaliberation necessary.\\(2.\\) (One sample test, Raw values) know mean sepal length setosas (species irises) 4.8 cm. new study examines sample 50 flowers shows sample mean 5.006 cm. Conduct one-tailed hypothesis test \\(.05\\) significance level show sufficient evidence reject hypothesis mean new sample equal 4.8 cm.\\(α = .05\\)\\(H_0: \\mu = 4.8\\)\\(H_A: \\mu > 4.8\\)Use following code store 50 values sample variable called setosa. (works iris built-dataset R.)[Ans]Test statistic: \\(z=\\frac{\\bar{X} - \\mu_0}{s/\\sqrt{n}}\\)Since 6.986e-05 < 0.05 , reject null hypothesis. sufficient evidence true mean setosa sepal length greater 4.8 cm.","code":"\nz <- (9.85-10)/(1/sqrt(25))\nz## [1] -0.75\npval <- pnorm(z)*2\npval## [1] 0.4532547\nsetosa <- iris[iris$Species == \"setosa\",]\nz <- (mean(setosa$Sepal.Length)-4.8)/sqrt(var(setosa$Sepal.Length)/50)\nz## [1] 4.132433\npval <- 1- pnorm(z)\npval## [1] 1.794718e-05\n# simpler approach\n# p-values might be a bit different due to approximation of t\nt.test(setosa$Sepal.Length, alternative = \"greater\", mu = 4.8)## \n##  One Sample t-test\n## \n## data:  setosa$Sepal.Length\n## t = 4.1324, df = 49, p-value = 6.986e-05\n## alternative hypothesis: true mean is greater than 4.8\n## 95 percent confidence interval:\n##  4.922425      Inf\n## sample estimates:\n## mean of x \n##     5.006"},{"path":"ch.-9-inferences-based-on-two-samples.html","id":"ch.-9-inferences-based-on-two-samples","chapter":"Ch. 9 Inferences Based on Two Samples","heading":"Ch. 9 Inferences Based on Two Samples","text":"Sections covered: 9.1, 9.4","code":""},{"path":"ch.-9-inferences-based-on-two-samples.html","id":"z-tests-and-cis-for-a-difference-between-two-population-means","chapter":"Ch. 9 Inferences Based on Two Samples","heading":"9.1 \\(z\\) Tests and CI’s for a Difference Between Two Population Means","text":"(Cases 1 & 2)Skip: p. 365 (“Using Comparison…”) end sectionWe consider tests \\(\\delta_0 = 0\\).","code":""},{"path":"ch.-9-inferences-based-on-two-samples.html","id":"inferences-concerning-a-difference-between-population-proportions","chapter":"Ch. 9 Inferences Based on Two Samples","heading":"9.4 Inferences Concerning a Difference Between Population Proportions","text":"Skip: p. 394 (“Type II Error Probabilities…”) end section","code":""},{"path":"ch.-9-inferences-based-on-two-samples.html","id":"r-4","chapter":"Ch. 9 Inferences Based on Two Samples","heading":"R","text":"/B Testing question class:","code":"\nclicks <- c(25, 20)\npeople <- c(100, 100)\nprop.test(clicks, people, correct = FALSE)## \n##  2-sample test for equality of proportions without continuity correction\n## \n## data:  clicks out of people\n## X-squared = 0.71685, df = 1, p-value = 0.3972\n## alternative hypothesis: two.sided\n## 95 percent confidence interval:\n##  -0.06553817  0.16553817\n## sample estimates:\n## prop 1 prop 2 \n##   0.25   0.20"},{"path":"ch.-2-conditional-probability.html","id":"ch.-2-conditional-probability","chapter":"Ch. 2 Conditional Probability","heading":"Ch. 2 Conditional Probability","text":"Sections covered: 2.4, 2.5(Section 2.5 covered earlier; now ’re adding definition independence terms conditional probability p. 85: “Two events B independent P(|B) = P() dependent otherwise.”)","code":""},{"path":"ch.-2-conditional-probability.html","id":"resources","chapter":"Ch. 2 Conditional Probability","heading":"Resources","text":"Extra practice problems, Bayes Theorem(Posted Twitter response Bill Gates’ provocative comment ’d rather encounter shark mosquito wild.)Intuitive (Short) Explanation Bayes’ Theorem","code":""},{"path":"ch.-5-joint-probability.html","id":"ch.-5-joint-probability","chapter":"Ch. 5 Joint Probability","heading":"Ch. 5 Joint Probability","text":"Sections covered: 5.1, 5.2","code":""},{"path":"ch.-5-joint-probability.html","id":"jointly-distributed-random-variables","chapter":"Ch. 5 Joint Probability","heading":"5.1 Jointly Distributed Random Variables","text":"Skip everything “Two Discrete Random Variables” pp. 199-200and “Independent Random Variables” pp. 204-205 (discrete case )Click anywhere graph add points. correlation coefficient calculated.\ncorrelation coefficient (r) measure linear relationship\ntwo variables x y. get sense connection \nappearance points – (x,y) pairs – scatterplot value r,\nclick anywhere graph add points. remove points, click Remove\npoints button mouseover points.\n\n Add points\n Remove points\n\nTwo points needed calculate r.\n","code":""},{"path":"ch.-5-joint-probability.html","id":"interactive","chapter":"Ch. 5 Joint Probability","heading":"Interactive","text":"Click anywhere graph add points. correlation coefficient calculated.\ncorrelation coefficient (r) measure linear relationship\ntwo variables x y. get sense connection \nappearance points – (x,y) pairs – scatterplot value r,\nclick anywhere graph add points. remove points, click Remove\npoints button mouseover points.\n\n Add points\n Remove points\n\nTwo points needed calculate r.\n","code":""},{"path":"ch.-5-joint-probability.html","id":"expected-values-covariance-and-correlation","chapter":"Ch. 5 Joint Probability","heading":"0.1 5.2 Expected Values, Covariance, and Correlation","text":"Skip everything “Covariance” pp. 214-216 “Correlation” pp. 216-218Re: “Covariance” section: focus concept covariance explained text. need know formulas examples pp. 214-215.","code":""},{"path":"ch.-5-joint-probability.html","id":"resources-1","chapter":"Ch. 5 Joint Probability","heading":"Resources","text":"Correlation Covariance Visualizationhttps://shiny.rit.albany.edu/stat/rectangles/","code":""},{"path":"ch.-14-chi-squared-test.html","id":"ch.-14-chi-squared-test","chapter":"Ch. 14 Chi Squared Test","heading":"Ch. 14 Chi Squared Test","text":"Sections covered: 14.3","code":""},{"path":"ch.-14-chi-squared-test.html","id":"two-way-contingency-tables","chapter":"Ch. 14 Chi Squared Test","heading":"14.3 Two-Way Contingency Tables","text":"Skip: pp. 639-643, including “Testing Homogeneity”Focus “Testing Independence (Lack Association)”Notes chi square test formula p. 644:Write null hypothesis sentence, book. (example: “Class Survival Status independent.”)Write null hypothesis sentence, book. (example: “Class Survival Status independent.”)“estimated expected” textbook “expected” used class“estimated expected” textbook “expected” used class\\(\\) \\(j\\) refer number rows columns table\\(\\) \\(j\\) refer number rows columns table","code":""},{"path":"ch.-14-chi-squared-test.html","id":"resources-2","chapter":"Ch. 14 Chi Squared Test","heading":"Resources","text":"Chi Square CalculatorChi Square Table","code":""},{"path":"ch.-12-linear-regression.html","id":"ch.-12-linear-regression","chapter":"Ch. 12 Linear Regression","heading":"Ch. 12 Linear Regression","text":"Sections covered: 12.1, 12.2, 12.5","code":""},{"path":"ch.-12-linear-regression.html","id":"the-simple-linear-regression-model","chapter":"Ch. 12 Linear Regression","heading":"12.1 The Simple Linear Regression Model","text":"","code":""},{"path":"ch.-12-linear-regression.html","id":"estimating-model-parameters","chapter":"Ch. 12 Linear Regression","heading":"12.2 Estimating Model Parameters","text":"Formulas know p. 498:\\(b_1 = \\dfrac{\\sum(x_i -\\overline{x})(y_i - \\overline{y})}{\\sum(x_i - \\overline{x})^2} = \\frac{S_{xy}}{S_{xx}}\\) \\(b_0 = \\overline{y} - b_1 \\overline{x}\\)Formula know p. 502:\\(SSE = \\sum(y_i - \\hat{y_i})^2\\)Formulas know p. 504:\\(SST = \\sum(y_i - \\overline{y})^2\\) \\(r^2 = 1 - \\frac{SSE}{SST}\\)Formulas know p. 505:\\(SSR = \\sum(\\hat{y_i} - \\overline{y})^2\\) \\(SSE + SSR = SST\\)","code":""},{"path":"ch.-12-linear-regression.html","id":"resources-3","chapter":"Ch. 12 Linear Regression","heading":"Resources","text":"Interactive Visualization: Linear Regression Try fitting least squares line set random data check answer (another one).Video: Regression : regression? | SSE, SSR, SST | R-squared | Errors (ε vs. e)","code":""},{"path":"ch.-12-linear-regression.html","id":"textbook-p.-507-17","chapter":"Ch. 12 Linear Regression","heading":"Textbook p. 507 #17","text":"Researchers fitted simple linear regression model explain \\(Y=\\) porosity (%) related \\(X=\\) unit weight (pcf) concrete specimens. Consider following representative data:Using R find:Model coefficients, \\(b_0\\) \\(b_1\\):(\\(b_0\\) listed (Intercept) \\(b_1\\) listed x.)Residualsrounded:SSR, SSE, SSTSSR (regression sum squares):SSE (error sum squares):SST (total sum squares):(Check SSR + SSE = SST)proportion observed variation porosity can attributed approximate linear relationship unit weight porosity?Method #1: SSR/SSTMethod #2: \\(r^2\\)","code":"\nx <- c(99.0, 101.1, 102.7, 103.0, 105.4, 107.0, 108.7, 110.8, 112.1, 112.4, 113.6, 113.8, 115.1, 115.4, 120.0)\ny <- c(28.8, 27.9, 27.0, 25.2, 22.8, 21.5, 20.9, 19.6, 17.1, 18.9, 16.0, 16.7, 13.0, 13.6, 10.8)\nmod <- lm(y ~ x)\nmod$coefficients## (Intercept)           x \n## 118.9099168  -0.9047307\nmod$residuals##          1          2          3          4          5          6          7 \n## -0.5415817  0.4583527  1.0059218 -0.5226590 -0.7513055 -0.6037364  0.3343057 \n##          8          9         10         11         12         13         14 \n##  0.9342401 -0.3896101  1.6818091 -0.1325141  0.7484321 -1.7754181 -0.9039989 \n##         15 \n##  0.4577621\nround(mod$residuals, 2)##     1     2     3     4     5     6     7     8     9    10    11    12    13 \n## -0.54  0.46  1.01 -0.52 -0.75 -0.60  0.33  0.93 -0.39  1.68 -0.13  0.75 -1.78 \n##    14    15 \n## -0.90  0.46\nSSR <- sum((mod$fitted.values - mean(y))^2)\nSSR## [1] 426.6185\nSSE <- sum(mod$residuals^2)\nSSE## [1] 11.43883\nSST <- sum((y - mean(y))^2)\nSST## [1] 438.0573\nSSR + SSE  ## [1] 438.0573\nSSR/SST## [1] 0.9738874\ncor(x, y)^2## [1] 0.9738874"},{"path":"ch.-12-linear-regression.html","id":"correlation","chapter":"Ch. 12 Linear Regression","heading":"12.5 Correlation","text":"Skip: p. 530 “Inferences Population Correlation Coefficient” end section.","code":""},{"path":"ch.-12-linear-regression.html","id":"resources-4","chapter":"Ch. 12 Linear Regression","heading":"Resources","text":"Interactive visualization: Correlation Coefficient (add remove points)Interactive visualization: Interpreting Correlations","code":""},{"path":"ch.-12-linear-regression.html","id":"r-5","chapter":"Ch. 12 Linear Regression","heading":"R","text":"Sample correlation coefficient \\(r\\)","code":"\n# Example 12.15, p. 528\nx <- c(2.4, 3.4, 4.6, 3.7, 2.2, 3.3, 4.0, 2.1)\ny <- c(1.33, 2.12, 1.80, 1.65, 2.00, 1.76, 2.11, 1.63)\n\ncor(x,y)## [1] 0.3472602"},{"path":"ch.-13-nonlinear-and-multiple-regression.html","id":"ch.-13-nonlinear-and-multiple-regression","chapter":"Ch. 13 Nonlinear and Multiple Regression","heading":"Ch. 13 Nonlinear and Multiple Regression","text":"Sections covered: 13.1","code":""},{"path":"ch.-13-nonlinear-and-multiple-regression.html","id":"assessing-model-adequacy","chapter":"Ch. 13 Nonlinear and Multiple Regression","heading":"13.1 Assessing Model Adequacy","text":"Skip: standardized residualsResiduals plots: know \\(e\\) vs. \\(x\\) onlyDifficulties remedies: 1. - 4. – know difficulties, remediesSkip: weighted least squares (p. 547)","code":""}]
